{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773debcd",
   "metadata": {},
   "source": [
    "# Évaluation d'un système de recommandation My Content\n",
    "\n",
    "Notebook pour entraîner et comparer plusieurs approches de recommandation sur le dataset Kaggle **news-portal-user-interactions-by-globocom**. L'objectif est de montrer clairement chaque étape (du chargement des données jusqu'au choix final du modèle)."
   ]
  },
  {
   "cell_type": "code",
   "id": "43aa8131",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:53.682258Z",
     "iopub.status.busy": "2025-12-17T10:07:53.681987Z",
     "iopub.status.idle": "2025-12-17T10:07:55.146794Z",
     "shell.execute_reply": "2025-12-17T10:07:55.145979Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:07.271747Z",
     "start_time": "2025-12-17T12:28:07.234810Z"
    }
   },
   "source": [
    "# Imports & Config\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Tuple, Union\n",
    "import optuna\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"clicks_dir\": \"../data/news-portal-user-interactions-by-globocom/clicks\",\n",
    "    \"metadata_path\": \"../data/news-portal-user-interactions-by-globocom/articles_metadata.csv\",\n",
    "    \"embeddings_path\": \"../data/news-portal-user-interactions-by-globocom/articles_embeddings.pickle\",\n",
    "    \"max_click_files\": 12,\n",
    "    \"artifacts_dir\": \"../artifacts/evaluation\",\n",
    "    \"k\": 5,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"recent_window_days\": 7,\n",
    "    \"random_seed\": 42,\n",
    "    \"svd_components\": 64,\n",
    "    \"content_pca_components\": None,\n",
    "    \"covisit_top_n_neighbors\": 20,\n",
    "    \"covisit_similarity\": \"cosine\",\n",
    "    \"covisit_hybrid_alpha\": 0.7350738721058192,\n",
    "    \"svd_hazard_ndcg\": 0.02,\n",
    "}\n",
    "np.random.seed(CONFIG[\"random_seed\"])\n",
    "Path(CONFIG[\"artifacts_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Config ready\", CONFIG)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config ready {'clicks_dir': '../data/news-portal-user-interactions-by-globocom/clicks', 'metadata_path': '../data/news-portal-user-interactions-by-globocom/articles_metadata.csv', 'embeddings_path': '../data/news-portal-user-interactions-by-globocom/articles_embeddings.pickle', 'max_click_files': 12, 'artifacts_dir': '../artifacts/evaluation', 'k': 5, 'train_ratio': 0.8, 'recent_window_days': 7, 'random_seed': 42, 'svd_components': 64, 'content_pca_components': None, 'covisit_top_n_neighbors': 20, 'covisit_similarity': 'cosine', 'covisit_hybrid_alpha': 0.7350738721058192, 'svd_hazard_ndcg': 0.02}\n"
     ]
    }
   ],
   "execution_count": 186
  },
  {
   "cell_type": "markdown",
   "id": "cc6be6a7",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "Nous voulons proposer à chaque lecteur un Top-5 d'articles susceptibles de l'intéresser. Le notebook illustre la démarche de A à Z : préparation des données, construction de différentes familles de modèles puis comparaison à l'aide de métriques de ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f8cfa",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les fichiers attendus sont situés dans `/data/*`."
   ]
  },
  {
   "cell_type": "code",
   "id": "116743e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.150007Z",
     "iopub.status.busy": "2025-12-17T10:07:55.149650Z",
     "iopub.status.idle": "2025-12-17T10:07:55.178749Z",
     "shell.execute_reply": "2025-12-17T10:07:55.177740Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:07.641261Z",
     "start_time": "2025-12-17T12:28:07.296840Z"
    }
   },
   "source": [
    "# Load data utilities\n",
    "\n",
    "def detect_timestamp_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Detect the timestamp-like column name.\"\"\"\n",
    "    candidates = [\"click_timestamp\", \"timestamp\", \"event_time\", \"ts\", \"time\"]\n",
    "    for col in df.columns:\n",
    "        if col in candidates or col.lower() in candidates:\n",
    "            return col\n",
    "    raise ValueError(\"No timestamp-like column found. Expected one of: \" + \",\".join(candidates))\n",
    "\n",
    "\n",
    "def detect_article_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Detect the article/item column name.\"\"\"\n",
    "    candidates = [\"click_article_id\", \"clicked_article_id\", \"article_id\", \"item_id\", \"content_id\"]\n",
    "    for col in df.columns:\n",
    "        if col in candidates:\n",
    "            return col\n",
    "    raise ValueError(\"No article id column found. Expected one of: \" + \",\".join(candidates))\n",
    "\n",
    "\n",
    "def infer_unix_unit(values: pd.Series) -> str:\n",
    "    numeric = pd.to_numeric(values, errors=\"coerce\").dropna()\n",
    "    if numeric.empty:\n",
    "        return \"s\"\n",
    "    max_abs = numeric.abs().max()\n",
    "    if max_abs >= 1e14:\n",
    "        return \"ns\"\n",
    "    if max_abs >= 1e11:\n",
    "        return \"ms\"\n",
    "    return \"s\"\n",
    "\n",
    "\n",
    "def to_timestamp(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return pd.to_datetime(series)\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        unit = infer_unix_unit(series)\n",
    "        return pd.to_datetime(series, unit=unit, errors=\"coerce\")\n",
    "\n",
    "    converted = pd.to_datetime(series, errors=\"coerce\")\n",
    "    if converted.notna().any():\n",
    "        return converted\n",
    "\n",
    "    unit = infer_unix_unit(series)\n",
    "    return pd.to_datetime(series, unit=unit, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def list_click_files(path: Union[str, Path]) -> List[Path]:\n",
    "    path_obj = Path(path)\n",
    "    if path_obj.is_file():\n",
    "        return [path_obj]\n",
    "    if path_obj.is_dir():\n",
    "        return sorted(path_obj.glob(\"clicks_hour_*.csv\"))\n",
    "    return []\n",
    "\n",
    "\n",
    "def create_synthetic_clicks(path: str, n_users: int = 50, n_items: int = 120, days: int = 30, interactions_per_user: int = 25) -> pd.DataFrame:\n",
    "    \"\"\"Create a small synthetic clicks dataset to keep the notebook runnable.\"\"\"\n",
    "    rng = np.random.default_rng(CONFIG[\"random_seed\"])\n",
    "    start = pd.Timestamp(\"2022-01-01\")\n",
    "    records = []\n",
    "    for user in range(1, n_users + 1):\n",
    "        offsets = rng.integers(0, days, size=interactions_per_user)\n",
    "        timestamps = [start + pd.Timedelta(int(o), unit=\"D\") for o in sorted(offsets.tolist())]\n",
    "        articles = rng.integers(1, n_items + 1, size=interactions_per_user)\n",
    "        for ts, art in zip(timestamps, articles):\n",
    "            records.append({\"user_id\": int(user), \"article_id\": int(art), \"timestamp\": ts})\n",
    "    df = pd.DataFrame(records).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\n",
    "        f\"Synthetic clicks dataset created at {path} \"\n",
    "        f\"(users={n_users}, items={n_items}, interactions={len(df)})\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_clicks(path: str, max_files: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Load clicks data from the Globo hourly files, with a safety cap.\"\"\"\n",
    "    files = list_click_files(path)\n",
    "    if not files:\n",
    "        print(f\"Clicks directory not found at {path}. Generating a synthetic sample for demonstration.\")\n",
    "        return create_synthetic_clicks(Path(path) / \"clicks_hour_000.csv\")\n",
    "\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        ts_col = detect_timestamp_column(df)\n",
    "        article_col = detect_article_column(df)\n",
    "        df[ts_col] = to_timestamp(df[ts_col])\n",
    "        df = df.rename(columns={ts_col: \"timestamp\", article_col: \"article_id\"})\n",
    "        frames.append(df[[\"user_id\", \"article_id\", \"timestamp\"]])\n",
    "\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    return combined.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_metadata(path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load article metadata if available.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Metadata file not found at {path}. Falling back to co-visitation content model.\")\n",
    "        return None\n",
    "    meta = pd.read_csv(path)\n",
    "    if \"article_id\" not in meta.columns:\n",
    "        print(\"Metadata missing 'article_id' column. Ignoring metadata.\")\n",
    "        return None\n",
    "    return meta\n",
    "\n",
    "\n",
    "clicks = load_clicks(CONFIG[\"clicks_dir\"], max_files=CONFIG[\"max_click_files\"])\n",
    "metadata = load_metadata(CONFIG[\"metadata_path\"])\n",
    "print(clicks.head())\n",
    "print(\"Metadata loaded:\", metadata is not None)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id  article_id               timestamp\n",
      "0       59      234853 2017-10-01 03:00:00.026\n",
      "1       79      159359 2017-10-01 03:00:01.702\n",
      "2      154       96663 2017-10-01 03:00:04.207\n",
      "3      111      202436 2017-10-01 03:00:14.140\n",
      "4       70      119592 2017-10-01 03:00:18.863\n",
      "Metadata loaded: True\n"
     ]
    }
   ],
   "execution_count": 187
  },
  {
   "cell_type": "markdown",
   "id": "eab18f0f",
   "metadata": {},
   "source": [
    "## Analyse exploratoire des données\n",
    "\n",
    "Courte photographie des fichiers sources immédiatement après le chargement :\n",
    "- nombre de lignes et noms de colonnes des clics\n",
    "- volumes et intégrité des métadonnées articles\n",
    "- dimensions et structure du fichier d'`articles_embeddings`."
   ]
  },
  {
   "cell_type": "code",
   "id": "45108db9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.182450Z",
     "iopub.status.busy": "2025-12-17T10:07:55.182242Z",
     "iopub.status.idle": "2025-12-17T10:07:55.260458Z",
     "shell.execute_reply": "2025-12-17T10:07:55.259678Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:08.899166Z",
     "start_time": "2025-12-17T12:28:07.652430Z"
    }
   },
   "source": [
    "# EDA rapide sur les données sources\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections.abc import Mapping\n",
    "\n",
    "\n",
    "def summarize_timestamps(series: pd.Series):\n",
    "    series = pd.to_datetime(series)\n",
    "    daily = series.dt.date.value_counts().sort_index().rename_axis(\"date\").reset_index(name=\"nb_clicks\")\n",
    "    hourly = series.dt.hour.value_counts().sort_index().rename_axis(\"hour\").reset_index(name=\"nb_clicks\")\n",
    "    return series.min(), series.max(), daily, hourly\n",
    "\n",
    "\n",
    "def describe_structure(obj, prefix=\"embeddings\", max_depth=4):\n",
    "    entries = []\n",
    "\n",
    "    def add_entry(path, value, note=None):\n",
    "        entry = {\"chemin\": path, \"type\": type(value).__name__}\n",
    "        if hasattr(value, \"shape\"):\n",
    "            entry[\"shape\"] = tuple(getattr(value, \"shape\"))\n",
    "        elif hasattr(value, \"__len__\") and not isinstance(value, (str, bytes)):\n",
    "            entry[\"len\"] = len(value)\n",
    "        if hasattr(value, \"dtype\"):\n",
    "            entry[\"dtype\"] = str(getattr(value, \"dtype\"))\n",
    "        if note:\n",
    "            entry[\"note\"] = note\n",
    "        if isinstance(value, np.ndarray) and value.dtype.names:\n",
    "            entry[\"dtype_fields\"] = list(value.dtype.names)\n",
    "        if isinstance(value, np.ndarray) and value.ndim == 1 and len(value) > 0 and not isinstance(value[0], (np.ndarray, list, tuple, Mapping)):\n",
    "            entry[\"exemple\"] = repr(value[:3].tolist())\n",
    "        entries.append(entry)\n",
    "\n",
    "    def walk(value, path, depth):\n",
    "        add_entry(path, value)\n",
    "        if depth >= max_depth:\n",
    "            return\n",
    "        if isinstance(value, Mapping):\n",
    "            for k, v in value.items():\n",
    "                walk(v, f\"{path}.{k}\", depth + 1)\n",
    "        elif isinstance(value, (list, tuple, np.ndarray)) and not isinstance(value, (str, bytes)):\n",
    "            if len(value) > 0:\n",
    "                walk(value[0], f\"{path}[0]\", depth + 1)\n",
    "\n",
    "    walk(obj, prefix, 0)\n",
    "    return entries\n",
    "\n",
    "\n",
    "click_files = list_click_files(CONFIG[\"clicks_dir\"])\n",
    "print(f\"Nombre total de fichiers clicks détectés: {len(click_files)}\")\n",
    "if not click_files:\n",
    "    print(\"Aucun fichier clicks trouvé au chemin configuré. Vérifiez le téléchargement des données.\")\n",
    "\n",
    "files_for_eda = click_files[:2]\n",
    "per_file_stats = []\n",
    "for file in files_for_eda:\n",
    "    df_file = pd.read_csv(file)\n",
    "    ts_col = detect_timestamp_column(df_file)\n",
    "    article_col = detect_article_column(df_file)\n",
    "    timestamps = to_timestamp(df_file[ts_col])\n",
    "    per_file_stats.append(\n",
    "        {\n",
    "            \"fichier\": file.name,\n",
    "            \"nb_lignes\": len(df_file),\n",
    "            \"colonnes\": \", \".join(df_file.columns),\n",
    "            \"articles_uniques\": df_file[article_col].nunique(),\n",
    "            \"horodatage_min\": timestamps.min(),\n",
    "            \"horodatage_max\": timestamps.max(),\n",
    "        }\n",
    "    )\n",
    "if per_file_stats:\n",
    "    display(pd.DataFrame(per_file_stats))\n",
    "else:\n",
    "    print(\"Pas assez de fichiers pour réaliser une EDA détaillée par fichier.\")\n",
    "\n",
    "print(\"=== Clicks (agrégés) ===\")\n",
    "if clicks.empty:\n",
    "    print(\"Aucun clic chargé. Vérifier le chemin ou augmenter max_click_files.\")\n",
    "else:\n",
    "    clicks_summary = {\n",
    "        \"nb_lignes\": len(clicks),\n",
    "        \"colonnes\": \", \".join(clicks.columns),\n",
    "        \"utilisateurs_uniques\": clicks['user_id'].nunique() if 'user_id' in clicks else None,\n",
    "        \"articles_uniques\": clicks['article_id'].nunique() if 'article_id' in clicks else None,\n",
    "    }\n",
    "    display(pd.DataFrame([clicks_summary]))\n",
    "\n",
    "    total_articles = None\n",
    "    if metadata is not None and 'article_id' in metadata:\n",
    "        total_articles = metadata['article_id'].nunique()\n",
    "    elif 'article_id' in clicks:\n",
    "        total_articles = clicks['article_id'].nunique()\n",
    "\n",
    "    total_clients = clicks['user_id'].nunique() if 'user_id' in clicks else None\n",
    "    print(\"Synthèse globale (articles / clients)\")\n",
    "    display(pd.DataFrame([{\n",
    "        'nombre_total_articles': total_articles,\n",
    "        'nombre_total_clients': total_clients,\n",
    "    }]))\n",
    "\n",
    "    ts_min, ts_max, daily, hourly = summarize_timestamps(clicks['timestamp'])\n",
    "    display(pd.DataFrame([\n",
    "        {\n",
    "            'horodatage_min': ts_min,\n",
    "            'horodatage_max': ts_max,\n",
    "            'fenetre_jours': (ts_max - ts_min).days + 1,\n",
    "        }\n",
    "    ]))\n",
    "    print(\"Répartition par jour (jusqu'à 10 premières valeurs)\")\n",
    "    display(daily.head(10))\n",
    "    print(\"Répartition par heure (0-23)\")\n",
    "    display(hourly)\n",
    "\n",
    "print(\"=== Métadonnées des articles ===\")\n",
    "if metadata is None:\n",
    "    print(\"Aucun fichier metadata chargé.\")\n",
    "else:\n",
    "    meta_summary = {\n",
    "        \"nb_articles\": len(metadata),\n",
    "        \"colonnes\": \", \".join(metadata.columns),\n",
    "        \"articles_uniques\": metadata['article_id'].nunique() if 'article_id' in metadata else None,\n",
    "    }\n",
    "    display(pd.DataFrame([meta_summary]))\n",
    "    missing = metadata.isna().sum().sort_values(ascending=False)\n",
    "    display(missing.to_frame('valeurs_manquantes'))\n",
    "    if 'created_at_ts' in metadata.columns:\n",
    "        created = to_timestamp(metadata['created_at_ts'])\n",
    "        display(pd.DataFrame([{'premier_article': created.min(), 'dernier_article': created.max()}]))\n",
    "    if 'article_id' in metadata.columns:\n",
    "        overlap = set(clicks['article_id'].unique()) if 'article_id' in clicks.columns else set()\n",
    "        coverage = len(overlap & set(metadata['article_id'].unique()))\n",
    "        print(f\"Articles présents dans clicks et metadata: {coverage}\")\n",
    "\n",
    "\n",
    "print(\"=== Embeddings d'articles ===\")\n",
    "embeddings_path = Path(CONFIG['embeddings_path'])\n",
    "if embeddings_path.exists():\n",
    "    with embeddings_path.open('rb') as f:\n",
    "        embeddings_obj = pickle.load(f)\n",
    "    print(f\"Type chargé: {type(embeddings_obj)}\")\n",
    "\n",
    "    def summarize_matrix(mat):\n",
    "        stats = {\n",
    "            'shape': getattr(mat, 'shape', None),\n",
    "            'dtype': getattr(mat, 'dtype', None),\n",
    "        }\n",
    "\n",
    "        dim_values = []\n",
    "        shape = getattr(mat, 'shape', None)\n",
    "        if shape is not None and len(shape) >= 2:\n",
    "            dim_values.append(shape[1])\n",
    "        elif isinstance(mat, (list, tuple, np.ndarray)):\n",
    "            for row in mat:\n",
    "                if hasattr(row, '__len__') and not isinstance(row, (str, bytes)):\n",
    "                    try:\n",
    "                        dim_values.append(len(row))\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "        if dim_values:\n",
    "            stats.update({\n",
    "                'profondeur_min': min(dim_values),\n",
    "                'profondeur_moyenne': float(np.mean(dim_values)),\n",
    "                'profondeur_max': max(dim_values),\n",
    "            })\n",
    "\n",
    "        if hasattr(mat, 'shape') and len(getattr(mat, 'shape', [])) == 2:\n",
    "            norms = np.linalg.norm(mat, axis=1)\n",
    "            stats.update(\n",
    "                {\n",
    "                    'nb_vectors': mat.shape[0],\n",
    "                    'dim': mat.shape[1],\n",
    "                    'norm_min': norms.min(),\n",
    "                    'norm_max': norms.max(),\n",
    "                    'norm_moyenne': norms.mean(),\n",
    "                }\n",
    "            )\n",
    "        return stats\n",
    "\n",
    "    base_structure = describe_structure(embeddings_obj, max_depth=4)\n",
    "\n",
    "    if isinstance(embeddings_obj, dict):\n",
    "        keys = list(embeddings_obj.keys())\n",
    "        print(f\"Clés disponibles: {keys}\")\n",
    "        matrix = embeddings_obj.get('embeddings')\n",
    "        ids = embeddings_obj.get('articles_ids') or embeddings_obj.get('article_ids')\n",
    "\n",
    "        structure = base_structure.copy()\n",
    "        if ids is not None:\n",
    "            structure.insert(0, {\n",
    "                'chemin': 'embeddings.article_ids',\n",
    "                'type': type(ids).__name__,\n",
    "                'len': len(ids),\n",
    "                'note': \"Identifiants d'articles fournis dans le fichier\",\n",
    "            })\n",
    "        if structure:\n",
    "            print(\"Structure détaillée de l'objet d'embeddings (par chemin de clé):\")\n",
    "            display(pd.DataFrame(structure))\n",
    "\n",
    "        if matrix is not None:\n",
    "            stats = summarize_matrix(matrix)\n",
    "            stats.update(\n",
    "                {\n",
    "                    'colonnes': \", \".join(keys),\n",
    "                    'nb_articles_ids': len(ids) if ids is not None else None,\n",
    "                    'ids_uniques': len(set(ids)) if ids is not None else None,\n",
    "                    'couverture_metadata': len(set(ids) & set(metadata['article_id']))\n",
    "                    if (metadata is not None and ids is not None and 'article_id' in metadata)\n",
    "                    else None,\n",
    "                    'couverture_clicks': len(set(ids) & set(clicks['article_id']))\n",
    "                    if (not clicks.empty and ids is not None and 'article_id' in clicks)\n",
    "                    else None,\n",
    "                }\n",
    "            )\n",
    "            display(pd.DataFrame([stats]))\n",
    "\n",
    "            if ids is not None:\n",
    "                sample_ids = ids[:5] if len(ids) >= 5 else ids\n",
    "                print(\"Aperçu des premiers article_id liés aux embeddings:\")\n",
    "                display(pd.DataFrame({'article_id': sample_ids}))\n",
    "\n",
    "            preview_cols = [f\"emb_{i}\" for i in range(min(5, matrix.shape[1] if hasattr(matrix, 'shape') else 0))]\n",
    "            if preview_cols:\n",
    "                preview = pd.DataFrame(matrix[:5, : len(preview_cols)], columns=preview_cols)\n",
    "                if ids is not None:\n",
    "                    preview.insert(0, 'article_id', ids[: len(preview)])\n",
    "                print(\"Aperçu des embeddings (quelques colonnes et premières lignes):\")\n",
    "                display(preview)\n",
    "                print(\"Colonnes affichées pour l'aperçu des embeddings:\")\n",
    "                print(\", \".join(preview.columns))\n",
    "\n",
    "                if ids is not None and metadata is not None and 'article_id' in metadata:\n",
    "                    meta_cols = [c for c in ['title', 'category_id', 'created_at_ts', 'publisher'] if c in metadata.columns]\n",
    "                    meta_sample = (\n",
    "                        preview[['article_id']]\n",
    "                        .merge(metadata[['article_id'] + meta_cols], on='article_id', how='left')\n",
    "                    )\n",
    "                    if 'created_at_ts' in meta_sample.columns:\n",
    "                        meta_sample['created_at_ts'] = to_timestamp(meta_sample['created_at_ts'])\n",
    "                    print(\"Exemple de liaison embedding -> metadata sur article_id (5 premières lignes):\")\n",
    "                    display(meta_sample.head())\n",
    "        else:\n",
    "            print(\"Aucune matrice d'embeddings explicite trouvée dans l'objet chargé.\")\n",
    "    elif hasattr(embeddings_obj, 'shape'):\n",
    "        stats = summarize_matrix(embeddings_obj)\n",
    "\n",
    "        inferred_ids = None\n",
    "        mapping_note = None\n",
    "        if metadata is not None and 'article_id' in metadata and hasattr(embeddings_obj, 'shape'):\n",
    "            if embeddings_obj.shape[0] == len(metadata):\n",
    "                inferred_ids = metadata['article_id'].reset_index(drop=True)\n",
    "                mapping_note = (\n",
    "                    \"Aucun article_id explicite fourni ; association supposée alignée sur l'ordre des metadata.\"\n",
    "                )\n",
    "            else:\n",
    "                mapping_note = (\n",
    "                    \"Aucun article_id dans le fichier d'embeddings et la taille ne correspond pas aux metadata : \"\n",
    "                    f\"{embeddings_obj.shape[0]} vecteurs vs {len(metadata)} lignes de metadata.\"\n",
    "                )\n",
    "        else:\n",
    "            mapping_note = (\n",
    "                \"Aucun identifiant d'article n'est présent dans le fichier d'embeddings (mapping externe requis).\"\n",
    "            )\n",
    "\n",
    "        structure = base_structure.copy()\n",
    "        if inferred_ids is not None:\n",
    "            structure.insert(0, {\n",
    "                'chemin': 'embeddings.article_id (inféré)',\n",
    "                'type': type(inferred_ids).__name__,\n",
    "                'len': len(inferred_ids),\n",
    "                'note': \"Alignement supposé sur metadata.article_id (index identique).\",\n",
    "            })\n",
    "        if structure:\n",
    "            print(\"Structure détaillée de l'objet d'embeddings (par chemin de clé):\")\n",
    "            display(pd.DataFrame(structure))\n",
    "\n",
    "        if mapping_note:\n",
    "            print(mapping_note)\n",
    "\n",
    "        if inferred_ids is not None:\n",
    "            stats.update(\n",
    "                {\n",
    "                    'ids_source': 'metadata.article_id (alignement par index)',\n",
    "                    'ids_uniques': inferred_ids.nunique(),\n",
    "                    'couverture_metadata': len(set(inferred_ids) & set(metadata['article_id'])),\n",
    "                    'couverture_clicks': len(set(inferred_ids) & set(clicks['article_id'])) if not clicks.empty else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        display(pd.DataFrame([stats]))\n",
    "        if len(getattr(embeddings_obj, 'shape', [])) >= 2 and embeddings_obj.shape[1] > 0:\n",
    "            preview_cols = [f\"emb_{i}\" for i in range(min(5, embeddings_obj.shape[1]))]\n",
    "            preview = pd.DataFrame(embeddings_obj[:5, : len(preview_cols)], columns=preview_cols)\n",
    "            if inferred_ids is not None:\n",
    "                preview.insert(0, 'article_id', inferred_ids.iloc[: len(preview)].values)\n",
    "            print(\"Aperçu direct de la matrice d'embeddings:\")\n",
    "            display(preview)\n",
    "            print(\"Colonnes affichées pour l'aperçu des embeddings:\")\n",
    "            print(\", \".join(preview.columns))\n",
    "\n",
    "            if inferred_ids is not None and metadata is not None:\n",
    "                meta_cols = [c for c in ['title', 'category_id', 'created_at_ts', 'publisher'] if c in metadata.columns]\n",
    "                meta_sample = preview[['article_id']].merge(\n",
    "                    metadata[['article_id'] + meta_cols], on='article_id', how='left'\n",
    "                )\n",
    "                if 'created_at_ts' in meta_sample.columns:\n",
    "                    meta_sample['created_at_ts'] = to_timestamp(meta_sample['created_at_ts'])\n",
    "                print(\"Exemple de liaison embedding -> metadata sur article_id (inféré):\")\n",
    "                display(meta_sample.head())\n",
    "        else:\n",
    "            print(\"Objet chargé non structuré, utilisez type/len pour investiguer.\")\n",
    "else:\n",
    "    print(f\"Fichier d'embeddings introuvable à {embeddings_path}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre total de fichiers clicks détectés: 385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "               fichier  nb_lignes  \\\n",
       "0  clicks_hour_000.csv       1883   \n",
       "1  clicks_hour_001.csv       1415   \n",
       "\n",
       "                                                                                                                                                                                colonnes  \\\n",
       "0  user_id, session_id, session_start, session_size, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type   \n",
       "1  user_id, session_id, session_start, session_size, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type   \n",
       "\n",
       "   articles_uniques          horodatage_min          horodatage_max  \n",
       "0               323 2017-10-01 03:00:00.026 2017-10-03 02:35:54.157  \n",
       "1               289 2017-10-01 03:36:28.615 2017-10-02 02:41:03.190  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fichier</th>\n",
       "      <th>nb_lignes</th>\n",
       "      <th>colonnes</th>\n",
       "      <th>articles_uniques</th>\n",
       "      <th>horodatage_min</th>\n",
       "      <th>horodatage_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>clicks_hour_000.csv</td>\n",
       "      <td>1883</td>\n",
       "      <td>user_id, session_id, session_start, session_size, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type</td>\n",
       "      <td>323</td>\n",
       "      <td>2017-10-01 03:00:00.026</td>\n",
       "      <td>2017-10-03 02:35:54.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>clicks_hour_001.csv</td>\n",
       "      <td>1415</td>\n",
       "      <td>user_id, session_id, session_start, session_size, click_article_id, click_timestamp, click_environment, click_deviceGroup, click_os, click_country, click_region, click_referrer_type</td>\n",
       "      <td>289</td>\n",
       "      <td>2017-10-01 03:36:28.615</td>\n",
       "      <td>2017-10-02 02:41:03.190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Clicks (agrégés) ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   nb_lignes                        colonnes  utilisateurs_uniques  \\\n",
       "0      31987  user_id, article_id, timestamp                 11642   \n",
       "\n",
       "   articles_uniques  \n",
       "0              1826  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_lignes</th>\n",
       "      <th>colonnes</th>\n",
       "      <th>utilisateurs_uniques</th>\n",
       "      <th>articles_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31987</td>\n",
       "      <td>user_id, article_id, timestamp</td>\n",
       "      <td>11642</td>\n",
       "      <td>1826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthèse globale (articles / clients)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   nombre_total_articles  nombre_total_clients\n",
       "0                 364047                 11642"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nombre_total_articles</th>\n",
       "      <th>nombre_total_clients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364047</td>\n",
       "      <td>11642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "           horodatage_min          horodatage_max  fenetre_jours\n",
       "0 2017-10-01 03:00:00.026 2017-10-05 02:26:43.525              4"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>horodatage_min</th>\n",
       "      <th>horodatage_max</th>\n",
       "      <th>fenetre_jours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01 03:00:00.026</td>\n",
       "      <td>2017-10-05 02:26:43.525</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition par jour (jusqu'à 10 premières valeurs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         date  nb_clicks\n",
       "0  2017-10-01      31872\n",
       "1  2017-10-02        106\n",
       "2  2017-10-03          6\n",
       "3  2017-10-04          1\n",
       "4  2017-10-05          2"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>nb_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>31872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-02</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-05</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Répartition par heure (0-23)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    hour  nb_clicks\n",
       "0      0         23\n",
       "1      1         19\n",
       "2      2         22\n",
       "3      3       2227\n",
       "4      4       1259\n",
       "5      5        810\n",
       "6      6        537\n",
       "7      7        618\n",
       "8      8        947\n",
       "9      9       2257\n",
       "10    10       3571\n",
       "11    11       5042\n",
       "12    12       5378\n",
       "13    13       5112\n",
       "14    14       3303\n",
       "15    15        346\n",
       "16    16        118\n",
       "17    17         84\n",
       "18    18         57\n",
       "19    19         51\n",
       "20    20         62\n",
       "21    21         60\n",
       "22    22         52\n",
       "23    23         32"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>nb_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>3571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>5042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>5112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Métadonnées des articles ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   nb_articles  \\\n",
       "0       364047   \n",
       "\n",
       "                                                            colonnes  \\\n",
       "0  article_id, category_id, created_at_ts, publisher_id, words_count   \n",
       "\n",
       "   articles_uniques  \n",
       "0            364047  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb_articles</th>\n",
       "      <th>colonnes</th>\n",
       "      <th>articles_uniques</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>364047</td>\n",
       "      <td>article_id, category_id, created_at_ts, publisher_id, words_count</td>\n",
       "      <td>364047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "               valeurs_manquantes\n",
       "article_id                      0\n",
       "category_id                     0\n",
       "created_at_ts                   0\n",
       "publisher_id                    0\n",
       "words_count                     0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>valeurs_manquantes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_at_ts</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publisher_id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>words_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "      premier_article     dernier_article\n",
       "0 2006-09-27 11:14:35 2018-03-13 12:12:30"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>premier_article</th>\n",
       "      <th>dernier_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-09-27 11:14:35</td>\n",
       "      <td>2018-03-13 12:12:30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles présents dans clicks et metadata: 1826\n",
      "=== Embeddings d'articles ===\n",
      "Type chargé: <class 'numpy.ndarray'>\n",
      "Structure détaillée de l'objet d'embeddings (par chemin de clé):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                           chemin     type       len  \\\n",
       "0  embeddings.article_id (inféré)   Series  364047.0   \n",
       "1                      embeddings  ndarray       NaN   \n",
       "2                   embeddings[0]  ndarray       NaN   \n",
       "3                embeddings[0][0]  float32       NaN   \n",
       "\n",
       "                                                            note  \\\n",
       "0  Alignement supposé sur metadata.article_id (index identique).   \n",
       "1                                                            NaN   \n",
       "2                                                            NaN   \n",
       "3                                                            NaN   \n",
       "\n",
       "           shape    dtype  \\\n",
       "0            NaN      NaN   \n",
       "1  (364047, 250)  float32   \n",
       "2         (250,)  float32   \n",
       "3             ()  float32   \n",
       "\n",
       "                                                             exemple  \n",
       "0                                                                NaN  \n",
       "1                                                                NaN  \n",
       "2  [-0.16118301451206207, -0.9572331309318542, -0.13794444501399994]  \n",
       "3                                                                NaN  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chemin</th>\n",
       "      <th>type</th>\n",
       "      <th>len</th>\n",
       "      <th>note</th>\n",
       "      <th>shape</th>\n",
       "      <th>dtype</th>\n",
       "      <th>exemple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>embeddings.article_id (inféré)</td>\n",
       "      <td>Series</td>\n",
       "      <td>364047.0</td>\n",
       "      <td>Alignement supposé sur metadata.article_id (index identique).</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>embeddings</td>\n",
       "      <td>ndarray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(364047, 250)</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embeddings[0]</td>\n",
       "      <td>ndarray</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(250,)</td>\n",
       "      <td>float32</td>\n",
       "      <td>[-0.16118301451206207, -0.9572331309318542, -0.13794444501399994]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>embeddings[0][0]</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>()</td>\n",
       "      <td>float32</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aucun article_id explicite fourni ; association supposée alignée sur l'ordre des metadata.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "           shape    dtype  profondeur_min  profondeur_moyenne  profondeur_max  \\\n",
       "0  (364047, 250)  float32             250               250.0             250   \n",
       "\n",
       "   nb_vectors  dim  norm_min  norm_max  norm_moyenne  \\\n",
       "0      364047  250  1.845483  11.18309      7.939456   \n",
       "\n",
       "                                   ids_source  ids_uniques  \\\n",
       "0  metadata.article_id (alignement par index)       364047   \n",
       "\n",
       "   couverture_metadata  couverture_clicks  \n",
       "0               364047               1826  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shape</th>\n",
       "      <th>dtype</th>\n",
       "      <th>profondeur_min</th>\n",
       "      <th>profondeur_moyenne</th>\n",
       "      <th>profondeur_max</th>\n",
       "      <th>nb_vectors</th>\n",
       "      <th>dim</th>\n",
       "      <th>norm_min</th>\n",
       "      <th>norm_max</th>\n",
       "      <th>norm_moyenne</th>\n",
       "      <th>ids_source</th>\n",
       "      <th>ids_uniques</th>\n",
       "      <th>couverture_metadata</th>\n",
       "      <th>couverture_clicks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(364047, 250)</td>\n",
       "      <td>float32</td>\n",
       "      <td>250</td>\n",
       "      <td>250.0</td>\n",
       "      <td>250</td>\n",
       "      <td>364047</td>\n",
       "      <td>250</td>\n",
       "      <td>1.845483</td>\n",
       "      <td>11.18309</td>\n",
       "      <td>7.939456</td>\n",
       "      <td>metadata.article_id (alignement par index)</td>\n",
       "      <td>364047</td>\n",
       "      <td>364047</td>\n",
       "      <td>1826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu direct de la matrice d'embeddings:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   article_id     emb_0     emb_1     emb_2     emb_3     emb_4\n",
       "0           0 -0.161183 -0.957233 -0.137944  0.050855  0.830055\n",
       "1           1 -0.523216 -0.974058  0.738608  0.155234  0.626294\n",
       "2           2 -0.619619 -0.972960 -0.207360 -0.128861  0.044748\n",
       "3           3 -0.740843 -0.975749  0.391698  0.641738 -0.268645\n",
       "4           4 -0.279052 -0.972315  0.685374  0.113056  0.238315"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>emb_0</th>\n",
       "      <th>emb_1</th>\n",
       "      <th>emb_2</th>\n",
       "      <th>emb_3</th>\n",
       "      <th>emb_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.161183</td>\n",
       "      <td>-0.957233</td>\n",
       "      <td>-0.137944</td>\n",
       "      <td>0.050855</td>\n",
       "      <td>0.830055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.523216</td>\n",
       "      <td>-0.974058</td>\n",
       "      <td>0.738608</td>\n",
       "      <td>0.155234</td>\n",
       "      <td>0.626294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0.619619</td>\n",
       "      <td>-0.972960</td>\n",
       "      <td>-0.207360</td>\n",
       "      <td>-0.128861</td>\n",
       "      <td>0.044748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.740843</td>\n",
       "      <td>-0.975749</td>\n",
       "      <td>0.391698</td>\n",
       "      <td>0.641738</td>\n",
       "      <td>-0.268645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0.279052</td>\n",
       "      <td>-0.972315</td>\n",
       "      <td>0.685374</td>\n",
       "      <td>0.113056</td>\n",
       "      <td>0.238315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes affichées pour l'aperçu des embeddings:\n",
      "article_id, emb_0, emb_1, emb_2, emb_3, emb_4\n",
      "Exemple de liaison embedding -> metadata sur article_id (inféré):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   article_id  category_id       created_at_ts\n",
       "0           0            0 2017-12-13 05:53:39\n",
       "1           1            1 2014-07-14 12:45:36\n",
       "2           2            1 2014-08-22 00:35:06\n",
       "3           3            1 2014-08-19 17:11:53\n",
       "4           4            1 2014-08-03 13:06:11"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>created_at_ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-13 05:53:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-07-14 12:45:36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-22 00:35:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-19 17:11:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-08-03 13:06:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 188
  },
  {
   "cell_type": "markdown",
   "id": "bac08d578ddc9073",
   "metadata": {},
   "source": [
    "# Article Embeddings\n",
    "\n",
    "Ce fichier contient les **embeddings des articles**, c’est-à-dire une **représentation numérique du contenu textuel** permettant de comparer les articles entre eux sur le plan sémantique.\n",
    "\n",
    "* **Format** : matrice NumPy `(N, 250)` en `float32`\n",
    "* **1 ligne = 1 article**\n",
    "* **250 colonnes = dimensions latentes**\n",
    "* Les valeurs individuelles n’ont pas de signification directe\n",
    "\n",
    "L’`article_id` n’est **pas stocké explicitement** : il est **déduit de l’ordre des lignes**, qui doit rester aligné avec les métadonnées des articles.\n",
    "\n",
    "La variable `words_count` indique le **nombre de mots du texte source** et sert uniquement d’indicateur de qualité du contenu.\n",
    "\n",
    "Les embeddings **ne sont pas normalisés** : la **similarité cosinus** est la mesure recommandée pour comparer les articles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26424a2",
   "metadata": {},
   "source": [
    "## Protocole\n",
    "\n",
    "1. Tri des interactions par horodatage pour respecter la chronologie.\n",
    "2. Split temporel train/test selon `train_ratio` afin d'éviter toute fuite du futur.\n",
    "3. Construction d'un profil utilisateur à partir des interactions de train.\n",
    "4. Définition du *ground truth* : articles cliqués en test pour chaque utilisateur (au moins un).\n",
    "5. Génération de recommandations Top-5 en excluant les articles déjà vus en train.\n",
    "6. Calcul des métriques de ranking (Precision@5, Recall@5, MAP@5, NDCG@5, Coverage@5) et estimation de la latence moyenne sur un échantillon de 500 utilisateurs max.\n",
    "\n",
    "Cette démarche imite un scénario de production : d'abord on respecte le temps, puis on mesure simultanément la qualité des suggestions et le coût de calcul."
   ]
  },
  {
   "cell_type": "code",
   "id": "a99221f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.263614Z",
     "iopub.status.busy": "2025-12-17T10:07:55.263340Z",
     "iopub.status.idle": "2025-12-17T10:07:55.299869Z",
     "shell.execute_reply": "2025-12-17T10:07:55.298572Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.599409Z",
     "start_time": "2025-12-17T12:28:09.312154Z"
    }
   },
   "source": [
    "# Split and utility functions\n",
    "\n",
    "def temporal_train_test_split(df: pd.DataFrame, train_ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split interactions chronologically according to the train_ratio.\"\"\"\n",
    "    cutoff = int(len(df) * train_ratio)\n",
    "    train = df.iloc[:cutoff].copy()\n",
    "    test = df.iloc[cutoff:].copy()\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def build_user_histories(df: pd.DataFrame) -> Dict[int, List[int]]:\n",
    "    \"\"\"Create mapping user -> list of articles in chronological order.\"\"\"\n",
    "    histories: Dict[int, List[int]] = {}\n",
    "    for user_id, group in df.groupby(\"user_id\"):\n",
    "        histories[int(user_id)] = group.sort_values(\"timestamp\")[\"article_id\"].tolist()\n",
    "    return histories\n",
    "\n",
    "\n",
    "def get_candidate_items(df: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"Return unique article ids.\"\"\"\n",
    "    return df[\"article_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "def make_ground_truth(train: pd.DataFrame, test: pd.DataFrame) -> Tuple[Dict[int, List[int]], Dict[int, List[int]]]:\n",
    "    \"\"\"Build user histories and ground truth for evaluation.\n",
    "\n",
    "    Only test items that were seen in training are kept so models are\n",
    "    evaluated on recommendable articles.\n",
    "    \"\"\"\n",
    "    train_hist = build_user_histories(train)\n",
    "    candidate_items = set(train[\"article_id\"].unique())\n",
    "    test_hist = build_user_histories(test)\n",
    "    filtered = {\n",
    "        u: [it for it in items if it in candidate_items]\n",
    "        for u, items in test_hist.items()\n",
    "        if u in train_hist and len(items) > 0\n",
    "    }\n",
    "    eligible_users = {u: items for u, items in filtered.items() if items}\n",
    "    return train_hist, eligible_users\n",
    "\n",
    "\n",
    "train_df, test_df = temporal_train_test_split(clicks, CONFIG[\"train_ratio\"])\n",
    "train_histories, ground_truth = make_ground_truth(train_df, test_df)\n",
    "candidate_items = get_candidate_items(train_df)\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}, Users for eval: {len(ground_truth)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 25589, Test size: 6398, Users for eval: 317\n"
     ]
    }
   ],
   "execution_count": 189
  },
  {
   "cell_type": "markdown",
   "id": "e35d6c96",
   "metadata": {},
   "source": [
    "## Métriques utilisées\n",
    "\n",
    "* **Precision@5** : part des recommandations top-5 qui sont réellement cliquées (plus c'est haut, plus le Top-5 est précis).\n",
    "* **Recall@5** : part des clics test retrouvés dans le Top-5 (mesure la couverture de ce que l'utilisateur aime).\n",
    "* **MAP@5** : moyenne de la précision cumulée à chaque clic retrouvé ; récompense les bonnes positions dans la liste.\n",
    "* **NDCG@5** : pondère chaque clic par sa position (gain décroissant) et normalise par le meilleur score possible ; idéal pour comparer des classements.\n",
    "* **Coverage@5** : proportion d'articles différents recommandés sur l'ensemble des utilisateurs (diversité du catalogue).\n",
    "* **Latence par utilisateur** : temps moyen pour produire le Top-5 (important pour une API temps réel)."
   ]
  },
  {
   "cell_type": "code",
   "id": "2bb3c598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.302388Z",
     "iopub.status.busy": "2025-12-17T10:07:55.302132Z",
     "iopub.status.idle": "2025-12-17T10:07:55.309858Z",
     "shell.execute_reply": "2025-12-17T10:07:55.308995Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.679098Z",
     "start_time": "2025-12-17T12:28:10.671904Z"
    }
   },
   "source": [
    "\n",
    "# Metrics\n",
    "\n",
    "def precision_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Precision@k for a single user.\"\"\"\n",
    "    if not recommended:\n",
    "        return 0.0\n",
    "    rec_k = recommended[:k]\n",
    "    hits = len(set(rec_k) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def recall_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Recall@k for a single user.\"\"\"\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    rec_k = recommended[:k]\n",
    "    hits = len(set(rec_k) & set(relevant))\n",
    "    return hits / len(relevant)\n",
    "\n",
    "\n",
    "def average_precision_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"MAP@k for a single user.\"\"\"\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, item in enumerate(recommended[:k], start=1):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(relevant), k)\n",
    "\n",
    "\n",
    "def dcg_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Discounted cumulative gain.\"\"\"\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k], start=1):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 1)\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Normalized DCG.\"\"\"\n",
    "    ideal_dcg = dcg_at_k(relevant[:k], relevant, k)\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0\n",
    "    return dcg_at_k(recommended, relevant, k) / ideal_dcg\n",
    "\n",
    "\n",
    "def coverage_at_k(all_recommendations: List[List[int]], candidate_items: List[int], k: int) -> float:\n",
    "    \"\"\"Coverage of unique recommended items over candidates.\"\"\"\n",
    "    rec_items = set()\n",
    "    for rec in all_recommendations:\n",
    "        rec_items.update(rec[:k])\n",
    "    if not candidate_items:\n",
    "        return 0.0\n",
    "    return len(rec_items) / len(candidate_items)\n"
   ],
   "outputs": [],
   "execution_count": 190
  },
  {
   "cell_type": "code",
   "id": "82f04b71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.312384Z",
     "iopub.status.busy": "2025-12-17T10:07:55.312125Z",
     "iopub.status.idle": "2025-12-17T10:07:55.341823Z",
     "shell.execute_reply": "2025-12-17T10:07:55.340786Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.759201Z",
     "start_time": "2025-12-17T12:28:10.732291Z"
    }
   },
   "source": [
    "# Recommenders\n",
    "\n",
    "def build_global_popularity(train: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"Return items sorted by global click counts.\"\"\"\n",
    "    return train.groupby(\"article_id\").size().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "def build_recent_popularity(train: pd.DataFrame, window_days: int) -> List[int]:\n",
    "    \"\"\"Return popular items over the last window_days of training data.\"\"\"\n",
    "    max_time = train[\"timestamp\"].max()\n",
    "    window_start = max_time - pd.Timedelta(days=window_days)\n",
    "    recent = train[train[\"timestamp\"] >= window_start]\n",
    "    if recent.empty:\n",
    "        return build_global_popularity(train)\n",
    "    counts = recent.groupby(\"article_id\")[\"timestamp\"].agg([\"size\", \"max\"])\n",
    "    ranked = counts.sort_values(by=[\"size\", \"max\"], ascending=[False, False])\n",
    "    return ranked.index.tolist()\n",
    "\n",
    "\n",
    "def build_covisit_graph(train: pd.DataFrame) -> Dict[int, Dict[int, int]]:\n",
    "    \"\"\"Build co-visitation counts based on user histories.\"\"\"\n",
    "    graph: Dict[int, Dict[int, int]] = {}\n",
    "    for _, group in train.groupby(\"user_id\"):\n",
    "        items = group.sort_values(\"timestamp\")[\"article_id\"].tolist()\n",
    "        unique_items = list(dict.fromkeys(items))\n",
    "        for i, item_i in enumerate(unique_items):\n",
    "            graph.setdefault(item_i, {})\n",
    "            for item_j in unique_items[i + 1 :]:\n",
    "                graph[item_i][item_j] = graph[item_i].get(item_j, 0) + 1\n",
    "                graph.setdefault(item_j, {})\n",
    "                graph[item_j][item_i] = graph[item_j].get(item_i, 0) + 1\n",
    "    return graph\n",
    "\n",
    "\n",
    "def build_content_embeddings(metadata: pd.DataFrame, pca_components: Optional[int] = None):\n",
    "    \"\"\"Create TF-IDF embeddings from textual columns with optional PCA reduction.\n",
    "\n",
    "    If no free-text columns are present, fall back to using non-ID columns as\n",
    "    categorical tokens so that content-based similarity remains available.\n",
    "    \"\"\"\n",
    "\n",
    "    text_cols = [\n",
    "        c\n",
    "        for c in metadata.columns\n",
    "        if metadata[c].dtype == object and c not in {\"article_id\", \"clicks\"}\n",
    "    ]\n",
    "    non_id_cols = [c for c in metadata.columns if c != \"article_id\"]\n",
    "\n",
    "    if not text_cols and non_id_cols:\n",
    "        print(\"No textual columns in metadata; using non-ID columns as categorical tokens.\")\n",
    "        text_cols = non_id_cols\n",
    "\n",
    "    if not text_cols:\n",
    "        raise ValueError(\"No usable columns in metadata to build content embeddings\")\n",
    "\n",
    "    corpus = metadata[text_cols].fillna(\"\")\n",
    "    corpus = corpus.apply(lambda row: \" \".join(f\"{col}_{val}\" for col, val in row.items()), axis=1)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    if pca_components and pca_components < tfidf.shape[1]:\n",
    "        svd = TruncatedSVD(n_components=pca_components, random_state=CONFIG[\"random_seed\"])\n",
    "        reduced = svd.fit_transform(tfidf)\n",
    "        embeddings = normalize(reduced)\n",
    "    else:\n",
    "        embeddings = normalize(tfidf)\n",
    "    ids = metadata[\"article_id\"].tolist()\n",
    "    return embeddings, ids\n",
    "\n",
    "\n",
    "def build_item_similarity(train: pd.DataFrame, metadata: Optional[pd.DataFrame]):\n",
    "    \"\"\"Build item-to-item similarity either from content or co-visitation.\"\"\"\n",
    "    if metadata is not None:\n",
    "        try:\n",
    "            embeddings, ids = build_content_embeddings(metadata, CONFIG[\"content_pca_components\"])\n",
    "            similarity: Dict[int, Dict[int, float]] = {}\n",
    "            for i, aid in enumerate(ids):\n",
    "                sims = embeddings @ embeddings[i].T\n",
    "                sims = np.asarray(sims).flatten()\n",
    "                top_idx = np.argsort(-sims)[1:51]\n",
    "                similarity[aid] = {ids[j]: float(sims[j]) for j in top_idx if sims[j] > 0}\n",
    "            return similarity, \"content\"\n",
    "        except Exception as exc:\n",
    "            print(f\"Content embeddings failed ({exc}). Falling back to co-visitation.\")\n",
    "    graph = build_covisit_graph(train)\n",
    "    similarity = {item: {nbr: float(cnt) for nbr, cnt in neigh.items()} for item, neigh in graph.items()}\n",
    "    return similarity, \"covisitation\"\n",
    "\n",
    "\n",
    "def recommend_from_similarity(user_id: int, train_histories: Dict[int, List[int]], similarity: Dict[int, Dict[int, float]], candidate_items: List[int], k: int) -> List[int]:\n",
    "    \"\"\"Aggregate similarity scores from user's history.\"\"\"\n",
    "    seen = set(train_histories.get(user_id, []))\n",
    "    scores: Dict[int, float] = {}\n",
    "    for item in seen:\n",
    "        for neighbor, sim in similarity.get(item, {}).items():\n",
    "            if neighbor in seen:\n",
    "                continue\n",
    "            scores[neighbor] = scores.get(neighbor, 0.0) + sim\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    recs = [it for it, _ in ranked if it not in seen]\n",
    "    if len(recs) < k:\n",
    "        for c in candidate_items:\n",
    "            if c not in seen and c not in recs:\n",
    "                recs.append(c)\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "    return recs[:k]\n",
    "\n",
    "\n",
    "def build_pure_covisit_similarity(train: pd.DataFrame, top_n_neighbors: int = 100, metric: str = \"cosine\") -> Dict[int, Dict[int, float]]:\n",
    "    \"\"\"Compute pure co-visitation similarity between items.\n",
    "\n",
    "    The function counts item pairs co-occurring in the same user history,\n",
    "    then converts counts to either cosine or Jaccard similarity and keeps\n",
    "    the top-N neighbors per item.\n",
    "    \"\"\"\n",
    "\n",
    "    histories = (\n",
    "        train.sort_values(\"timestamp\")\n",
    "        .groupby(\"user_id\")[\"article_id\"]\n",
    "        .apply(lambda s: list(dict.fromkeys(s.tolist())))\n",
    "    )\n",
    "    item_user_counts = train.groupby(\"article_id\")[\"user_id\"].nunique().to_dict()\n",
    "\n",
    "    co_counts: Dict[int, Dict[int, int]] = {}\n",
    "    for items in histories:\n",
    "        for i, item_i in enumerate(items):\n",
    "            for item_j in items[i + 1 :]:\n",
    "                if item_i == item_j:\n",
    "                    continue\n",
    "                co_counts.setdefault(item_i, {})\n",
    "                co_counts.setdefault(item_j, {})\n",
    "                co_counts[item_i][item_j] = co_counts[item_i].get(item_j, 0) + 1\n",
    "                co_counts[item_j][item_i] = co_counts[item_j].get(item_i, 0) + 1\n",
    "\n",
    "    similarity: Dict[int, Dict[int, float]] = {}\n",
    "    for item_i, neighbors in co_counts.items():\n",
    "        sims = []\n",
    "        for item_j, count in neighbors.items():\n",
    "            if metric == \"jaccard\":\n",
    "                denom = item_user_counts.get(item_i, 0) + item_user_counts.get(item_j, 0) - count\n",
    "                if denom <= 0:\n",
    "                    continue\n",
    "                sim = count / denom\n",
    "            else:\n",
    "                denom = np.sqrt(item_user_counts.get(item_i, 0) * item_user_counts.get(item_j, 0))\n",
    "                if denom == 0:\n",
    "                    continue\n",
    "                sim = count / denom\n",
    "            sims.append((item_j, float(sim)))\n",
    "        top_neighbors = sorted(sims, key=lambda x: x[1], reverse=True)[:top_n_neighbors]\n",
    "        similarity[item_i] = {j: sim for j, sim in top_neighbors}\n",
    "    return similarity\n",
    "\n",
    "\n",
    "def build_covisit_recommender(train: pd.DataFrame, top_n_neighbors: int = 100, metric: str = \"cosine\"):\n",
    "    \"\"\"Return a recommend function based purely on co-visitation similarity.\"\"\"\n",
    "\n",
    "    similarity = build_pure_covisit_similarity(train, top_n_neighbors=top_n_neighbors, metric=metric)\n",
    "    popularity = build_global_popularity(train)\n",
    "\n",
    "    def recommend(user_id: int, seen: set, k: int) -> List[int]:\n",
    "        scores: Dict[int, float] = {}\n",
    "        for item in seen:\n",
    "            for neighbor, sim in similarity.get(item, {}).items():\n",
    "                if neighbor in seen:\n",
    "                    continue\n",
    "                scores[neighbor] = scores.get(neighbor, 0.0) + sim\n",
    "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        recs = [it for it, _ in ranked]\n",
    "        if len(recs) < k:\n",
    "            for it in popularity:\n",
    "                if it not in seen and it not in recs:\n",
    "                    recs.append(it)\n",
    "                if len(recs) >= k:\n",
    "                    break\n",
    "        return recs[:k]\n",
    "\n",
    "    meta = {\"top_n_neighbors\": top_n_neighbors, \"metric\": metric, \"items\": len(similarity)}\n",
    "    return recommend, meta\n",
    "\n",
    "\n",
    "def build_collaborative_svd(train: pd.DataFrame, n_components: int):\n",
    "    \"\"\"Train a simple implicit SVD recommender returning a recommend function.\"\"\"\n",
    "    user_codes, user_index = pd.factorize(train[\"user_id\"], sort=True)\n",
    "    item_codes, item_index = pd.factorize(train[\"article_id\"], sort=True)\n",
    "\n",
    "    interactions = pd.DataFrame({\"user_idx\": user_codes, \"item_idx\": item_codes}).drop_duplicates()\n",
    "    data = np.ones(len(interactions), dtype=np.float32)\n",
    "    mat = sparse.coo_matrix((data, (interactions[\"user_idx\"], interactions[\"item_idx\"])), shape=(len(user_index), len(item_index))).tocsr()\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=CONFIG[\"random_seed\"])\n",
    "    user_factors = svd.fit_transform(mat)\n",
    "    item_factors = svd.components_.T\n",
    "\n",
    "    user_to_idx = {int(uid): int(idx) for idx, uid in enumerate(user_index.tolist())}\n",
    "    items = [int(aid) for aid in item_index.tolist()]\n",
    "\n",
    "    def recommend(user_id: int, seen: set, k: int) -> List[int]:\n",
    "        if user_id not in user_to_idx:\n",
    "            popularity = build_global_popularity(train)\n",
    "            return [it for it in popularity if it not in seen][:k]\n",
    "\n",
    "        u_vec = user_factors[user_to_idx[user_id]]\n",
    "        scores = item_factors @ u_vec\n",
    "        ranked_items = [items[i] for i in np.argsort(-scores)]\n",
    "        return [it for it in ranked_items if it not in seen][:k]\n",
    "\n",
    "    meta = {\"users\": len(user_index), \"items\": len(item_index), \"components\": n_components}\n",
    "    return recommend, meta\n",
    "\n",
    "\n",
    "def build_hybrid_covisit_recommender(\n",
    "    train: pd.DataFrame,\n",
    "    alpha: float,\n",
    "    top_n_neighbors: int = 100,\n",
    "    metric: str = \"cosine\",\n",
    "):\n",
    "    \"\"\"Return a hybrid recommender mixing pure co-visitation and popularity.\"\"\"\n",
    "\n",
    "    similarity = build_pure_covisit_similarity(\n",
    "        train,\n",
    "        top_n_neighbors=top_n_neighbors,\n",
    "        metric=metric,\n",
    "    )\n",
    "    popularity = build_global_popularity(train)\n",
    "    popularity_scores = train.groupby(\"article_id\").size()\n",
    "    max_pop = float(popularity_scores.max()) if not popularity_scores.empty else 0.0\n",
    "    popularity_scores = (popularity_scores / max_pop).to_dict() if max_pop > 0 else {}\n",
    "\n",
    "    def recommend(user_id: int, seen: set, k: int) -> List[int]:\n",
    "        scores: Dict[int, float] = {}\n",
    "        for item in seen:\n",
    "            for neighbor, sim in similarity.get(item, {}).items():\n",
    "                if neighbor in seen:\n",
    "                    continue\n",
    "                scores[neighbor] = scores.get(neighbor, 0.0) + alpha * sim\n",
    "        for item, pop_score in popularity_scores.items():\n",
    "            if item in seen:\n",
    "                continue\n",
    "            scores[item] = scores.get(item, 0.0) + (1 - alpha) * pop_score\n",
    "        ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        recs = [it for it, _ in ranked]\n",
    "        if len(recs) < k:\n",
    "            for it in popularity:\n",
    "                if it not in seen and it not in recs:\n",
    "                    recs.append(it)\n",
    "                if len(recs) >= k:\n",
    "                    break\n",
    "        return recs[:k]\n",
    "\n",
    "    meta = {\n",
    "        \"top_n_neighbors\": top_n_neighbors,\n",
    "        \"metric\": metric,\n",
    "        \"alpha\": alpha,\n",
    "        \"hybrid\": True,\n",
    "        \"items\": len(similarity),\n",
    "    }\n",
    "    return recommend, meta\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 191
  },
  {
   "cell_type": "code",
   "id": "a2a633fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.344174Z",
     "iopub.status.busy": "2025-12-17T10:07:55.343953Z",
     "iopub.status.idle": "2025-12-17T10:07:55.351668Z",
     "shell.execute_reply": "2025-12-17T10:07:55.350647Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.818691Z",
     "start_time": "2025-12-17T12:28:10.812624Z"
    }
   },
   "source": [
    "\n",
    "# Evaluation pipeline\n",
    "\n",
    "def evaluate_model(\n",
    "    name: str,\n",
    "    recommend_func: Callable[[int, set, int], List[int]],\n",
    "    train_histories: Dict[int, List[int]],\n",
    "    ground_truth: Dict[int, List[int]],\n",
    "    candidate_items: List[int],\n",
    "    k: int,\n",
    "    latency_sample: int = 500,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate a recommender with ranking metrics and latency estimation.\"\"\"\n",
    "    precisions: List[float] = []\n",
    "    recalls: List[float] = []\n",
    "    maps: List[float] = []\n",
    "    ndcgs: List[float] = []\n",
    "    all_recs: List[List[int]] = []\n",
    "\n",
    "    users = list(ground_truth.keys())\n",
    "    for user_id in users:\n",
    "        seen = set(train_histories.get(user_id, []))\n",
    "        recs = recommend_func(user_id, seen, k)\n",
    "        gt = ground_truth[user_id]\n",
    "        all_recs.append(recs)\n",
    "        precisions.append(precision_at_k(recs, gt, k))\n",
    "        recalls.append(recall_at_k(recs, gt, k))\n",
    "        maps.append(average_precision_at_k(recs, gt, k))\n",
    "        ndcgs.append(ndcg_at_k(recs, gt, k))\n",
    "\n",
    "    coverage = coverage_at_k(all_recs, candidate_items, k)\n",
    "\n",
    "    sample_users = users[: min(latency_sample, len(users))]\n",
    "    start = time.perf_counter()\n",
    "    for user_id in sample_users:\n",
    "        seen = set(train_histories.get(user_id, []))\n",
    "        _ = recommend_func(user_id, seen, k)\n",
    "    latency = (time.perf_counter() - start) / max(1, len(sample_users))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"users\": len(users),\n",
    "        \"precision@k\": float(np.mean(precisions)),\n",
    "        \"recall@k\": float(np.mean(recalls)),\n",
    "        \"map@k\": float(np.mean(maps)),\n",
    "        \"ndcg@k\": float(np.mean(ndcgs)),\n",
    "        \"coverage@k\": coverage,\n",
    "        \"latency_per_user_s\": latency,\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": 192
  },
  {
   "cell_type": "markdown",
   "id": "c71df81d",
   "metadata": {},
   "source": [
    "## Entraînement des systèmes de recommandation\n",
    "\n",
    "Chaque approche est entraînée séparément pour limiter le temps d'exécution de chaque cellule et mieux contextualiser le rôle de chaque modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f3017",
   "metadata": {},
   "source": [
    "### Popularité globale\n",
    "La recommandation par popularité globale trie les articles par volume d'interactions dans l'ensemble d'entraînement. Elle est rapide à calculer (simple agrégation) et sert de baseline robuste pour comparer les modèles plus avancés."
   ]
  },
  {
   "cell_type": "code",
   "id": "77fe52f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.354112Z",
     "iopub.status.busy": "2025-12-17T10:07:55.353890Z",
     "iopub.status.idle": "2025-12-17T10:07:55.359023Z",
     "shell.execute_reply": "2025-12-17T10:07:55.358108Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.890551Z",
     "start_time": "2025-12-17T12:28:10.885157Z"
    }
   },
   "source": [
    "# Configuration commune\n",
    "K = CONFIG[\"k\"]\n",
    "\n",
    "# Popularité globale\n",
    "popularity_rank = build_global_popularity(train_df)\n",
    "\n",
    "def popularity_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return [it for it in popularity_rank if it not in seen][:k]"
   ],
   "outputs": [],
   "execution_count": 193
  },
  {
   "cell_type": "markdown",
   "id": "3b431ac4",
   "metadata": {},
   "source": [
    "### Popularité récente\n",
    "Cette variante privilégie la fraîcheur en filtrant les interactions sur une fenêtre temporelle avant de trier les articles par fréquence. Utile pour capter les tendances du moment, au prix d'un recalcul plus fréquent de la fenêtre glissante."
   ]
  },
  {
   "cell_type": "code",
   "id": "13812520",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.361539Z",
     "iopub.status.busy": "2025-12-17T10:07:55.361319Z",
     "iopub.status.idle": "2025-12-17T10:07:55.370933Z",
     "shell.execute_reply": "2025-12-17T10:07:55.370040Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:10.957380Z",
     "start_time": "2025-12-17T12:28:10.945848Z"
    }
   },
   "source": [
    "# Popularité récente\n",
    "recent_rank = build_recent_popularity(train_df, CONFIG[\"recent_window_days\"])\n",
    "\n",
    "def recent_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return [it for it in recent_rank if it not in seen][:k]"
   ],
   "outputs": [],
   "execution_count": 194
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4833",
   "metadata": {},
   "source": [
    "### Collaborative (SVD)\n",
    "Le filtrage collaboratif factorise la matrice utilisateur-item (SVD) pour capturer des préférences latentes. L'entraînement est plus long que les méthodes de popularité ou de similarité de contenu, mais il modélise mieux les affinités implicites entre utilisateurs et articles."
   ]
  },
  {
   "cell_type": "code",
   "id": "2ffed396",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.373125Z",
     "iopub.status.busy": "2025-12-17T10:07:55.372900Z",
     "iopub.status.idle": "2025-12-17T10:07:55.394728Z",
     "shell.execute_reply": "2025-12-17T10:07:55.393807Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:12.373777Z",
     "start_time": "2025-12-17T12:28:11.001024Z"
    }
   },
   "source": [
    "# Filtrage collaboratif (SVD)\n",
    "collab_recommend, collab_meta = build_collaborative_svd(train_df, CONFIG[\"svd_components\"])\n",
    "\n",
    "def collaborative_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return collab_recommend(user_id, seen, k)"
   ],
   "outputs": [],
   "execution_count": 195
  },
  {
   "cell_type": "code",
   "id": "79d92ce4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.398003Z",
     "iopub.status.busy": "2025-12-17T10:07:55.397764Z",
     "iopub.status.idle": "2025-12-17T10:07:55.439170Z",
     "shell.execute_reply": "2025-12-17T10:07:55.438405Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:13.001235Z",
     "start_time": "2025-12-17T12:28:12.480462Z"
    }
   },
   "source": [
    "# Recommandation co-visitation pure\n",
    "covisit_recommend_func, covisit_meta = build_covisit_recommender(\n",
    "    train_df,\n",
    "    top_n_neighbors=CONFIG[\"covisit_top_n_neighbors\"],\n",
    "    metric=CONFIG[\"covisit_similarity\"],\n",
    ")\n",
    "\n",
    "def covisit_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return covisit_recommend_func(user_id, seen, k)\n"
   ],
   "outputs": [],
   "execution_count": 196
  },
  {
   "cell_type": "markdown",
   "id": "f83ee1f5",
   "metadata": {},
   "source": [
    "### Contenu (similarité article-article)\n",
    "Un modèle basé contenu construit une matrice de similarité entre articles à partir des métadonnées. Les recommandations se font en projetant l'historique utilisateur vers les items proches dans cet espace. Ce calcul peut être plus coûteux car il nécessite la vectorisation et le produit croisé des articles."
   ]
  },
  {
   "cell_type": "code",
   "id": "dc3f20fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.442352Z",
     "iopub.status.busy": "2025-12-17T10:07:55.441747Z",
     "iopub.status.idle": "2025-12-17T10:07:55.445954Z",
     "shell.execute_reply": "2025-12-17T10:07:55.445409Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:13.015053Z",
     "start_time": "2025-12-17T12:28:13.011838Z"
    }
   },
   "source": [
    "# Initialiser un conteneur de résultats pour chaque entraînement\n",
    "results = []\n",
    "step_results = []"
   ],
   "outputs": [],
   "execution_count": 197
  },
  {
   "cell_type": "code",
   "id": "fb98dec3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.448407Z",
     "iopub.status.busy": "2025-12-17T10:07:55.448189Z",
     "iopub.status.idle": "2025-12-17T10:07:55.500220Z",
     "shell.execute_reply": "2025-12-17T10:07:55.498609Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:13.079240Z",
     "start_time": "2025-12-17T12:28:13.075565Z"
    }
   },
   "source": [
    "# Recommandation basée contenu (désactivable)\n",
    "ENABLE_CONTENT_MODEL = False  # Passer à True pour activer le calcul de similarité contenu\n",
    "\n",
    "if ENABLE_CONTENT_MODEL:\n",
    "    item_similarity, sim_mode = build_item_similarity(train_df, metadata)\n",
    "\n",
    "    def content_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "        return recommend_from_similarity(user_id, train_histories, item_similarity, candidate_items, k)\n",
    "else:\n",
    "    sim_mode = \"désactivé\"\n",
    "    content_recommender = None\n"
   ],
   "outputs": [],
   "execution_count": 198
  },
  {
   "cell_type": "markdown",
   "id": "18f18670",
   "metadata": {},
   "source": [
    "## Entraînements séparés\n",
    "\n",
    "Les cinq stratégies sont désormais exécutées dans des cellules distinctes afin de pouvoir lancer, arrêter ou relancer chaque bloc indépendamment. Cela évite d'attendre l'ensemble du pipeline quand un seul entraînement est nécessaire.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92a2100",
   "metadata": {},
   "source": [
    "### Entraînement 1 : Baseline A – Popularité globale\n",
    "\n",
    "Cette approche classe les articles par nombre total de clics dans l'historique d'entraînement. Aucun paramètre n'est appris : on calcule simplement le classement global une fois, puis on recommande les articles les plus populaires que l'utilisateur n'a pas encore vus."
   ]
  },
  {
   "cell_type": "code",
   "id": "d861c1b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.503322Z",
     "iopub.status.busy": "2025-12-17T10:07:55.502453Z",
     "iopub.status.idle": "2025-12-17T10:07:55.517553Z",
     "shell.execute_reply": "2025-12-17T10:07:55.516294Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:13.166075Z",
     "start_time": "2025-12-17T12:28:13.134229Z"
    }
   },
   "source": [
    "popularity_result = evaluate_model(\n",
    "    \"Baseline A - Popularité globale\",\n",
    "    popularity_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(popularity_result)\n",
    "pd.DataFrame([popularity_result])\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                             model  users  precision@k  recall@k     map@k  \\\n",
       "0  Baseline A - Popularité globale    317     0.102208  0.228077  0.149125   \n",
       "\n",
       "     ndcg@k  coverage@k  latency_per_user_s  \n",
       "0  0.201729    0.006298            0.000029  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>users</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>map@k</th>\n",
       "      <th>ndcg@k</th>\n",
       "      <th>coverage@k</th>\n",
       "      <th>latency_per_user_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline A - Popularité globale</td>\n",
       "      <td>317</td>\n",
       "      <td>0.102208</td>\n",
       "      <td>0.228077</td>\n",
       "      <td>0.149125</td>\n",
       "      <td>0.201729</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.000029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 199
  },
  {
   "cell_type": "markdown",
   "id": "f7d9c4fe",
   "metadata": {},
   "source": [
    "### Entraînement 3 : Modèle C – Item2Item\n",
    "\n",
    "Le modèle item2item construit une matrice de similarité entre articles (TF-IDF contenu ou co-visitation suivant la disponibilité des métadonnées). Pour chaque utilisateur, on agrège les articles les plus proches de son historique en excluant les items déjà vus."
   ]
  },
  {
   "cell_type": "code",
   "id": "9c9df9f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.535540Z",
     "iopub.status.busy": "2025-12-17T10:07:55.535328Z",
     "iopub.status.idle": "2025-12-17T10:07:55.566970Z",
     "shell.execute_reply": "2025-12-17T10:07:55.566381Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:13.266852Z",
     "start_time": "2025-12-17T12:28:13.262539Z"
    }
   },
   "source": [
    "if not ENABLE_CONTENT_MODEL:\n",
    "    print(\"Modèle C - Item2Item désactivé (ENABLE_CONTENT_MODEL=False).\")\n",
    "else:\n",
    "    item2item_result = evaluate_model(\n",
    "        f\"Modèle C - Item2Item ({sim_mode})\",\n",
    "        content_recommender,\n",
    "        train_histories,\n",
    "        ground_truth,\n",
    "        candidate_items,\n",
    "        K,\n",
    "    )\n",
    "    results.append(item2item_result)\n",
    "    pd.DataFrame([item2item_result])\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle C - Item2Item désactivé (ENABLE_CONTENT_MODEL=False).\n"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "cell_type": "markdown",
   "id": "248cbed2",
   "metadata": {},
   "source": [
    "### Entraînement 4 : Modèle D – Collaborative SVD\n",
    "\n",
    "La factorisation de matrice SVD est évaluée après les approches à base de popularité/contenu. On conserve le mécanisme de vérification rapide : si la métrique reste sous le hazard, on stoppe la suite du pipeline pour éviter de consommer du temps sur des configurations mal alignées.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "73526056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.569369Z",
     "iopub.status.busy": "2025-12-17T10:07:55.569131Z",
     "iopub.status.idle": "2025-12-17T10:07:55.583727Z",
     "shell.execute_reply": "2025-12-17T10:07:55.583034Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:14.761892Z",
     "start_time": "2025-12-17T12:28:13.406320Z"
    }
   },
   "source": [
    "svd_result = evaluate_model(\n",
    "    \"Modèle D - Collaborative SVD\",\n",
    "    collaborative_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(svd_result)\n",
    "\n",
    "if svd_result[\"ndcg@k\"] < CONFIG[\"svd_hazard_ndcg\"]:\n",
    "    raise ValueError(\n",
    "        f\"NDCG@{K} du SVD = {svd_result['ndcg@k']:.4f}, sous le hazard {CONFIG['svd_hazard_ndcg']}. Vérifier l'alignement user/item.\"\n",
    "    )\n",
    "\n",
    "pd.DataFrame([svd_result])\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                          model  users  precision@k  recall@k     map@k  \\\n",
       "0  Modèle D - Collaborative SVD    317     0.011356  0.027918  0.020216   \n",
       "\n",
       "     ndcg@k  coverage@k  latency_per_user_s  \n",
       "0  0.026798    0.128761            0.002327  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>users</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>map@k</th>\n",
       "      <th>ndcg@k</th>\n",
       "      <th>coverage@k</th>\n",
       "      <th>latency_per_user_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modèle D - Collaborative SVD</td>\n",
       "      <td>317</td>\n",
       "      <td>0.011356</td>\n",
       "      <td>0.027918</td>\n",
       "      <td>0.020216</td>\n",
       "      <td>0.026798</td>\n",
       "      <td>0.128761</td>\n",
       "      <td>0.002327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 201
  },
  {
   "cell_type": "markdown",
   "id": "9f956cc1",
   "metadata": {},
   "source": [
    "### Entraînement 5 : Modèle E – Co-visitation pure\n",
    "\n",
    "Ce bloc calcule la similarité item-to-item par co-visitation et évalue la recommandation basée sur les co-occurrences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed9732e",
   "metadata": {},
   "source": [
    "#### Variantes retenues du modèle E\n",
    "\n",
    "Nous conservons deux déclinaisons simples :\n",
    "\n",
    "- **E0** : co-visitation pure.\n",
    "- **E3** : hybride léger mélangeant E0 et la popularité globale (pondération `alpha`).\n",
    "\n",
    "Les variantes **E1** (pondération temporelle des co-visites) et **E2** (normalisation lift/PMI pour corriger la popularité brute) ont été écartées : elles n'apportaient pas d'amélioration significative et dégradaient légèrement les métriques par rapport à E0/E3.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "3ef6f2ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.585957Z",
     "iopub.status.busy": "2025-12-17T10:07:55.585654Z",
     "iopub.status.idle": "2025-12-17T10:07:55.616949Z",
     "shell.execute_reply": "2025-12-17T10:07:55.615926Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:15.005056Z",
     "start_time": "2025-12-17T12:28:14.989415Z"
    }
   },
   "source": [
    "covisit_result = evaluate_model(\n",
    "    f\"Modèle E0 - Co-visitation pure ({CONFIG['covisit_similarity']})\",\n",
    "    covisit_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(covisit_result)\n",
    "step_results.append({**covisit_result, \"model\": \"E0\"})\n",
    "pd.DataFrame([covisit_result])\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                     model  users  precision@k  recall@k  \\\n",
       "0  Modèle E0 - Co-visitation pure (cosine)    317     0.085174  0.191802   \n",
       "\n",
       "      map@k    ndcg@k  coverage@k  latency_per_user_s  \n",
       "0  0.109802  0.157127    0.160952            0.000008  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>users</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>map@k</th>\n",
       "      <th>ndcg@k</th>\n",
       "      <th>coverage@k</th>\n",
       "      <th>latency_per_user_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modèle E0 - Co-visitation pure (cosine)</td>\n",
       "      <td>317</td>\n",
       "      <td>0.085174</td>\n",
       "      <td>0.191802</td>\n",
       "      <td>0.109802</td>\n",
       "      <td>0.157127</td>\n",
       "      <td>0.160952</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 202
  },
  {
   "cell_type": "markdown",
   "id": "58e5a088",
   "metadata": {},
   "source": [
    "### Variante E3 : hybride co-visitation + popularité"
   ]
  },
  {
   "cell_type": "code",
   "id": "f4ac6422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.620010Z",
     "iopub.status.busy": "2025-12-17T10:07:55.619446Z",
     "iopub.status.idle": "2025-12-17T10:07:55.680096Z",
     "shell.execute_reply": "2025-12-17T10:07:55.679543Z"
    },
    "ExecuteTime": {
     "end_time": "2025-12-17T12:28:15.461286Z",
     "start_time": "2025-12-17T12:28:15.118101Z"
    }
   },
   "source": [
    "hybrid_recommend, hybrid_meta = build_hybrid_covisit_recommender(\n",
    "    train_df,\n",
    "    alpha=CONFIG[\"covisit_hybrid_alpha\"],\n",
    "    top_n_neighbors=CONFIG[\"covisit_top_n_neighbors\"],\n",
    "    metric=CONFIG[\"covisit_similarity\"],\n",
    ")\n",
    "\n",
    "def hybrid_covisit_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return hybrid_recommend(user_id, seen, k)\n",
    "\n",
    "\n",
    "E3_result = evaluate_model(\n",
    "    f\"Modèle E3 - Hybride (alpha={CONFIG['covisit_hybrid_alpha']})\",\n",
    "    hybrid_covisit_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(E3_result)\n",
    "step_results.append({**E3_result, \"model\": \"E3\"})\n",
    "pd.DataFrame([E3_result])\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            model  users  precision@k  \\\n",
       "0  Modèle E3 - Hybride (alpha=0.7350738721058192)    317     0.106625   \n",
       "\n",
       "   recall@k     map@k    ndcg@k  coverage@k  latency_per_user_s  \n",
       "0  0.236574  0.150994  0.205068     0.06648            0.000297  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>users</th>\n",
       "      <th>precision@k</th>\n",
       "      <th>recall@k</th>\n",
       "      <th>map@k</th>\n",
       "      <th>ndcg@k</th>\n",
       "      <th>coverage@k</th>\n",
       "      <th>latency_per_user_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Modèle E3 - Hybride (alpha=0.7350738721058192)</td>\n",
       "      <td>317</td>\n",
       "      <td>0.106625</td>\n",
       "      <td>0.236574</td>\n",
       "      <td>0.150994</td>\n",
       "      <td>0.205068</td>\n",
       "      <td>0.06648</td>\n",
       "      <td>0.000297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 203
  },
  {
   "cell_type": "code",
   "id": "20a86678",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-17T12:29:24.267157Z",
     "start_time": "2025-12-17T12:28:15.722891Z"
    }
   },
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from typing import Any, Dict, Callable\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "N_TRIALS = 1000\n",
    "BASELINE_LATENCY_S = 0.05  # ajuste si tu as une baseline mesurée\n",
    "\n",
    "def composite_score(\n",
    "    eval_result: Dict[str, float],\n",
    "    baseline_latency_s: float,\n",
    "    w_ndcg: float = 1.0,\n",
    "    w_coverage: float = 0.2,\n",
    "    w_latency: float = 0.05,\n",
    ") -> float:\n",
    "    ndcg = float(eval_result[\"ndcg@k\"])\n",
    "    coverage = float(eval_result[\"coverage@k\"])\n",
    "    latency = float(eval_result[\"latency_per_user_s\"])\n",
    "    latency_ratio = latency / max(baseline_latency_s, 1e-9)\n",
    "    return (w_ndcg * ndcg) + (w_coverage * coverage) - (w_latency * latency_ratio)\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    alpha = trial.suggest_float(\"covisit_hybrid_alpha\", 0.0, 1.0)\n",
    "    top_n_neighbors = trial.suggest_int(\"covisit_top_n_neighbors\", 20, 1200, log=True)\n",
    "\n",
    "    recommend_fn, meta = build_hybrid_covisit_recommender(\n",
    "        train_df,\n",
    "        alpha=alpha,\n",
    "        top_n_neighbors=top_n_neighbors,\n",
    "        metric=CONFIG[\"covisit_similarity\"],\n",
    "    )\n",
    "\n",
    "    eval_result = evaluate_model(\n",
    "        f\"Modèle E3-1 - Hybride optuna (trial {trial.number})\",\n",
    "        recommend_fn,\n",
    "        train_histories,\n",
    "        ground_truth,\n",
    "        candidate_items,\n",
    "        K,\n",
    "    )\n",
    "\n",
    "    # Stocker toutes les infos dans Optuna (évite les listes globales)\n",
    "    trial.set_user_attr(\"eval_result\", eval_result)\n",
    "    trial.set_user_attr(\"meta\", meta)\n",
    "\n",
    "    score = composite_score(eval_result, baseline_latency_s=BASELINE_LATENCY_S)\n",
    "    trial.report(score, step=0)\n",
    "    if trial.should_prune():\n",
    "        raise optuna.TrialPruned()\n",
    "    return score\n",
    "\n",
    "sampler = TPESampler(seed=RANDOM_SEED, multivariate=True, group=True)\n",
    "pruner = MedianPruner(n_startup_trials=50)\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
    "study.optimize(objective, n_trials=N_TRIALS, show_progress_bar=True)\n",
    "\n",
    "best_params = study.best_params\n",
    "best_trial = study.best_trial\n",
    "best_eval = best_trial.user_attrs[\"eval_result\"]\n",
    "\n",
    "print(\"Meilleurs hyperparamètres :\", best_params)\n",
    "print(\"Score optimisé :\", study.best_value)\n",
    "\n",
    "# Rebuild final model with best params\n",
    "best_recommend, best_meta = build_hybrid_covisit_recommender(\n",
    "    train_df,\n",
    "    alpha=float(best_params[\"covisit_hybrid_alpha\"]),\n",
    "    top_n_neighbors=int(best_params[\"covisit_top_n_neighbors\"]),\n",
    "    metric=CONFIG[\"covisit_similarity\"],\n",
    ")\n",
    "\n",
    "optimized_result = {**best_eval, \"model\": \"Modèle E3-1 - Hybride optimisé\"}\n",
    "results.append(optimized_result)\n",
    "step_results.append(optimized_result)\n",
    "\n",
    "pd.DataFrame([optimized_result])\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/scude/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``multivariate`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "/home/scude/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/_experimental.py:31: ExperimentalWarning: Argument ``group`` is an experimental feature. The interface can change in the future.\n",
      "  warnings.warn(\n",
      "[I 2025-12-17 13:28:15,729] A new study created in memory with name: no-name-c06cf3ba-3ce9-4a96-9664-4642719d0d36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b14aec87929a408e8b2f22d4f1da5d4a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-17 13:28:16,241] Trial 0 finished with value: 0.20185022074806336 and parameters: {'covisit_hybrid_alpha': 0.3745401188473625, 'covisit_top_n_neighbors': 980}. Best is trial 0 with value: 0.20185022074806336.\n",
      "[I 2025-12-17 13:28:16,745] Trial 1 finished with value: 0.2143997234437116 and parameters: {'covisit_hybrid_alpha': 0.7319939418114051, 'covisit_top_n_neighbors': 230}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:17,064] Trial 2 finished with value: 0.20121773772242646 and parameters: {'covisit_hybrid_alpha': 0.15601864044243652, 'covisit_top_n_neighbors': 37}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:17,448] Trial 3 finished with value: 0.20209124125969433 and parameters: {'covisit_hybrid_alpha': 0.05808361216819946, 'covisit_top_n_neighbors': 692}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:17,837] Trial 4 finished with value: 0.20913822053038603 and parameters: {'covisit_hybrid_alpha': 0.6011150117432088, 'covisit_top_n_neighbors': 361}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:18,194] Trial 5 finished with value: 0.20263669171272916 and parameters: {'covisit_hybrid_alpha': 0.020584494295802447, 'covisit_top_n_neighbors': 1061}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:18,587] Trial 6 finished with value: 0.21352541809703834 and parameters: {'covisit_hybrid_alpha': 0.8324426408004217, 'covisit_top_n_neighbors': 47}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:18,908] Trial 7 finished with value: 0.20122344159308608 and parameters: {'covisit_hybrid_alpha': 0.18182496720710062, 'covisit_top_n_neighbors': 42}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:19,225] Trial 8 finished with value: 0.20246655193215077 and parameters: {'covisit_hybrid_alpha': 0.3042422429595377, 'covisit_top_n_neighbors': 169}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:19,531] Trial 9 finished with value: 0.20289631554767315 and parameters: {'covisit_hybrid_alpha': 0.43194501864211576, 'covisit_top_n_neighbors': 65}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:19,898] Trial 10 finished with value: 0.20521982024087548 and parameters: {'covisit_hybrid_alpha': 0.9252914811972325, 'covisit_top_n_neighbors': 507}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:20,228] Trial 11 finished with value: 0.20774037242645862 and parameters: {'covisit_hybrid_alpha': 0.8990709698242456, 'covisit_top_n_neighbors': 98}. Best is trial 1 with value: 0.2143997234437116.\n",
      "[I 2025-12-17 13:28:20,589] Trial 12 finished with value: 0.2145066347939727 and parameters: {'covisit_hybrid_alpha': 0.6939457675753907, 'covisit_top_n_neighbors': 25}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:20,910] Trial 13 finished with value: 0.2097448642982786 and parameters: {'covisit_hybrid_alpha': 0.5937313673902672, 'covisit_top_n_neighbors': 43}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:21,219] Trial 14 finished with value: 0.21124107933231362 and parameters: {'covisit_hybrid_alpha': 0.5759252178310681, 'covisit_top_n_neighbors': 22}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:21,558] Trial 15 finished with value: 0.2113346999928391 and parameters: {'covisit_hybrid_alpha': 0.6152907235724258, 'covisit_top_n_neighbors': 127}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:21,922] Trial 16 finished with value: 0.2026560525802406 and parameters: {'covisit_hybrid_alpha': 0.01317673246334028, 'covisit_top_n_neighbors': 133}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:22,298] Trial 17 finished with value: 0.18979728744948166 and parameters: {'covisit_hybrid_alpha': 0.9963453785758216, 'covisit_top_n_neighbors': 35}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:22,638] Trial 18 finished with value: 0.21279892051295232 and parameters: {'covisit_hybrid_alpha': 0.7908030046367756, 'covisit_top_n_neighbors': 234}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:23,006] Trial 19 finished with value: 0.2111367387932184 and parameters: {'covisit_hybrid_alpha': 0.646421536137774, 'covisit_top_n_neighbors': 770}. Best is trial 12 with value: 0.2145066347939727.\n",
      "[I 2025-12-17 13:28:23,333] Trial 20 finished with value: 0.2145939178569326 and parameters: {'covisit_hybrid_alpha': 0.7270299396602468, 'covisit_top_n_neighbors': 64}. Best is trial 20 with value: 0.2145939178569326.\n",
      "[I 2025-12-17 13:28:23,639] Trial 21 finished with value: 0.21656651715375794 and parameters: {'covisit_hybrid_alpha': 0.7473151147586202, 'covisit_top_n_neighbors': 21}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:24,053] Trial 22 finished with value: 0.2146997420636246 and parameters: {'covisit_hybrid_alpha': 0.7620694105879353, 'covisit_top_n_neighbors': 24}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:24,371] Trial 23 finished with value: 0.21454227177617294 and parameters: {'covisit_hybrid_alpha': 0.7490666936780888, 'covisit_top_n_neighbors': 36}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:24,695] Trial 24 finished with value: 0.21267968762093384 and parameters: {'covisit_hybrid_alpha': 0.8630603071317442, 'covisit_top_n_neighbors': 23}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:25,037] Trial 25 finished with value: 0.21434661534969376 and parameters: {'covisit_hybrid_alpha': 0.7224064866072203, 'covisit_top_n_neighbors': 68}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:25,352] Trial 26 finished with value: 0.2095822053352368 and parameters: {'covisit_hybrid_alpha': 0.8511217354144737, 'covisit_top_n_neighbors': 20}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:25,657] Trial 27 finished with value: 0.2047366183178539 and parameters: {'covisit_hybrid_alpha': 0.480743091615775, 'covisit_top_n_neighbors': 35}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:26,040] Trial 28 finished with value: 0.21567008586802616 and parameters: {'covisit_hybrid_alpha': 0.7157837642768043, 'covisit_top_n_neighbors': 23}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:26,345] Trial 29 finished with value: 0.20374785941861945 and parameters: {'covisit_hybrid_alpha': 0.39286460730614503, 'covisit_top_n_neighbors': 20}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:26,676] Trial 30 finished with value: 0.21446277130759347 and parameters: {'covisit_hybrid_alpha': 0.6900052835623972, 'covisit_top_n_neighbors': 31}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:26,993] Trial 31 finished with value: 0.21522965753315965 and parameters: {'covisit_hybrid_alpha': 0.7736018352304251, 'covisit_top_n_neighbors': 21}. Best is trial 21 with value: 0.21656651715375794.\n",
      "[I 2025-12-17 13:28:27,295] Trial 32 finished with value: 0.217784348627467 and parameters: {'covisit_hybrid_alpha': 0.7324712492087523, 'covisit_top_n_neighbors': 21}. Best is trial 32 with value: 0.217784348627467.\n",
      "[I 2025-12-17 13:28:27,687] Trial 33 finished with value: 0.21565213497872301 and parameters: {'covisit_hybrid_alpha': 0.6932642306803081, 'covisit_top_n_neighbors': 21}. Best is trial 32 with value: 0.217784348627467.\n",
      "[I 2025-12-17 13:28:27,986] Trial 34 finished with value: 0.21035606047580363 and parameters: {'covisit_hybrid_alpha': 0.6291081429736294, 'covisit_top_n_neighbors': 20}. Best is trial 32 with value: 0.217784348627467.\n",
      "[I 2025-12-17 13:28:28,280] Trial 35 finished with value: 0.21341071808704054 and parameters: {'covisit_hybrid_alpha': 0.66173507186524, 'covisit_top_n_neighbors': 20}. Best is trial 32 with value: 0.217784348627467.\n",
      "[I 2025-12-17 13:28:28,624] Trial 36 finished with value: 0.2020569368395459 and parameters: {'covisit_hybrid_alpha': 0.37325834322568313, 'covisit_top_n_neighbors': 565}. Best is trial 32 with value: 0.217784348627467.\n",
      "[I 2025-12-17 13:28:28,931] Trial 37 finished with value: 0.21779753850128136 and parameters: {'covisit_hybrid_alpha': 0.7282877077006503, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:29,305] Trial 38 finished with value: 0.21208633541316768 and parameters: {'covisit_hybrid_alpha': 0.864032749492344, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:29,620] Trial 39 finished with value: 0.21291894381414414 and parameters: {'covisit_hybrid_alpha': 0.7195860382147287, 'covisit_top_n_neighbors': 51}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:29,934] Trial 40 finished with value: 0.2080722166885556 and parameters: {'covisit_hybrid_alpha': 0.8426372976714691, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:30,231] Trial 41 finished with value: 0.21342405444666518 and parameters: {'covisit_hybrid_alpha': 0.6642769116216598, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:30,526] Trial 42 finished with value: 0.21652072252622392 and parameters: {'covisit_hybrid_alpha': 0.7085776385678028, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:30,819] Trial 43 finished with value: 0.21491502301099089 and parameters: {'covisit_hybrid_alpha': 0.6910214403720562, 'covisit_top_n_neighbors': 22}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:31,189] Trial 44 finished with value: 0.21658647899555872 and parameters: {'covisit_hybrid_alpha': 0.7149001607785039, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:31,506] Trial 45 finished with value: 0.21674356533666797 and parameters: {'covisit_hybrid_alpha': 0.7330870290412377, 'covisit_top_n_neighbors': 22}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:31,836] Trial 46 finished with value: 0.20940399165324913 and parameters: {'covisit_hybrid_alpha': 0.8766963100117295, 'covisit_top_n_neighbors': 44}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:32,145] Trial 47 finished with value: 0.21202281560207203 and parameters: {'covisit_hybrid_alpha': 0.5631632876511204, 'covisit_top_n_neighbors': 42}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:32,452] Trial 48 finished with value: 0.2143122573168608 and parameters: {'covisit_hybrid_alpha': 0.7356937915673389, 'covisit_top_n_neighbors': 40}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:32,831] Trial 49 finished with value: 0.21146579758340844 and parameters: {'covisit_hybrid_alpha': 0.6426653760196612, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:33,136] Trial 50 finished with value: 0.2134712291913259 and parameters: {'covisit_hybrid_alpha': 0.7863641004487145, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:33,435] Trial 51 pruned. \n",
      "[I 2025-12-17 13:28:33,744] Trial 52 finished with value: 0.21757635421479093 and parameters: {'covisit_hybrid_alpha': 0.749328283871316, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:34,045] Trial 53 pruned. \n",
      "[I 2025-12-17 13:28:34,453] Trial 54 finished with value: 0.214133243351583 and parameters: {'covisit_hybrid_alpha': 0.7278560334460784, 'covisit_top_n_neighbors': 40}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:34,761] Trial 55 finished with value: 0.21269076153535577 and parameters: {'covisit_hybrid_alpha': 0.8559422820622641, 'covisit_top_n_neighbors': 36}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:35,076] Trial 56 finished with value: 0.21662976304297973 and parameters: {'covisit_hybrid_alpha': 0.7289215634370918, 'covisit_top_n_neighbors': 23}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:35,376] Trial 57 pruned. \n",
      "[I 2025-12-17 13:28:35,681] Trial 58 finished with value: 0.2140724539602085 and parameters: {'covisit_hybrid_alpha': 0.7666686244418205, 'covisit_top_n_neighbors': 34}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:36,001] Trial 59 finished with value: 0.21500336997778 and parameters: {'covisit_hybrid_alpha': 0.7070403875752227, 'covisit_top_n_neighbors': 22}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:36,389] Trial 60 pruned. \n",
      "[I 2025-12-17 13:28:36,696] Trial 61 finished with value: 0.21303762558415895 and parameters: {'covisit_hybrid_alpha': 0.6500236630952008, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:37,013] Trial 62 finished with value: 0.2169053715772491 and parameters: {'covisit_hybrid_alpha': 0.7580350394005411, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:37,354] Trial 63 finished with value: 0.21370294290282185 and parameters: {'covisit_hybrid_alpha': 0.7449855637495428, 'covisit_top_n_neighbors': 40}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:37,671] Trial 64 pruned. \n",
      "[I 2025-12-17 13:28:38,049] Trial 65 pruned. \n",
      "[I 2025-12-17 13:28:38,356] Trial 66 pruned. \n",
      "[I 2025-12-17 13:28:38,659] Trial 67 pruned. \n",
      "[I 2025-12-17 13:28:38,977] Trial 68 finished with value: 0.21307203219264537 and parameters: {'covisit_hybrid_alpha': 0.7535979577418733, 'covisit_top_n_neighbors': 40}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:39,294] Trial 69 finished with value: 0.21473628849641532 and parameters: {'covisit_hybrid_alpha': 0.6751480043397802, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:39,702] Trial 70 finished with value: 0.21343907527649938 and parameters: {'covisit_hybrid_alpha': 0.7862791036724337, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:40,030] Trial 71 finished with value: 0.21686766788051845 and parameters: {'covisit_hybrid_alpha': 0.7434442731079743, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:40,348] Trial 72 finished with value: 0.2145005445233502 and parameters: {'covisit_hybrid_alpha': 0.7498677033160789, 'covisit_top_n_neighbors': 35}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:40,655] Trial 73 pruned. \n",
      "[I 2025-12-17 13:28:40,959] Trial 74 finished with value: 0.21665721371174182 and parameters: {'covisit_hybrid_alpha': 0.7155508446905509, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:41,262] Trial 75 finished with value: 0.2169288901564973 and parameters: {'covisit_hybrid_alpha': 0.7202895064288068, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:41,647] Trial 76 pruned. \n",
      "[I 2025-12-17 13:28:41,948] Trial 77 finished with value: 0.21378672096638549 and parameters: {'covisit_hybrid_alpha': 0.7857321298064089, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:42,281] Trial 78 pruned. \n",
      "[I 2025-12-17 13:28:42,681] Trial 79 pruned. \n",
      "[I 2025-12-17 13:28:42,984] Trial 80 finished with value: 0.21613941883844 and parameters: {'covisit_hybrid_alpha': 0.7682328241402024, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:43,353] Trial 81 pruned. \n",
      "[I 2025-12-17 13:28:43,658] Trial 82 finished with value: 0.21589725698018566 and parameters: {'covisit_hybrid_alpha': 0.7069096738083285, 'covisit_top_n_neighbors': 20}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:43,969] Trial 83 pruned. \n",
      "[I 2025-12-17 13:28:44,324] Trial 84 pruned. \n",
      "[I 2025-12-17 13:28:44,629] Trial 85 pruned. \n",
      "[I 2025-12-17 13:28:45,021] Trial 86 pruned. \n",
      "[I 2025-12-17 13:28:45,330] Trial 87 finished with value: 0.2154170065046692 and parameters: {'covisit_hybrid_alpha': 0.7034254377546633, 'covisit_top_n_neighbors': 21}. Best is trial 37 with value: 0.21779753850128136.\n",
      "[I 2025-12-17 13:28:45,652] Trial 88 pruned. \n",
      "[I 2025-12-17 13:28:45,957] Trial 89 pruned. \n",
      "[I 2025-12-17 13:28:46,266] Trial 90 pruned. \n",
      "[I 2025-12-17 13:28:46,585] Trial 91 finished with value: 0.21779799175364672 and parameters: {'covisit_hybrid_alpha': 0.7264536340023707, 'covisit_top_n_neighbors': 21}. Best is trial 91 with value: 0.21779799175364672.\n",
      "[I 2025-12-17 13:28:46,952] Trial 92 pruned. \n",
      "[I 2025-12-17 13:28:47,270] Trial 93 finished with value: 0.21603246307231785 and parameters: {'covisit_hybrid_alpha': 0.766988648872452, 'covisit_top_n_neighbors': 21}. Best is trial 91 with value: 0.21779799175364672.\n",
      "[I 2025-12-17 13:28:47,590] Trial 94 pruned. \n",
      "[I 2025-12-17 13:28:47,959] Trial 95 finished with value: 0.2178538033815049 and parameters: {'covisit_hybrid_alpha': 0.7323197281981465, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:48,296] Trial 96 pruned. \n",
      "[I 2025-12-17 13:28:48,722] Trial 97 finished with value: 0.2150129676225562 and parameters: {'covisit_hybrid_alpha': 0.680435475212687, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:49,039] Trial 98 finished with value: 0.21548080107660694 and parameters: {'covisit_hybrid_alpha': 0.7718619576232418, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:49,352] Trial 99 pruned. \n",
      "[I 2025-12-17 13:28:49,681] Trial 100 pruned. \n",
      "[I 2025-12-17 13:28:49,990] Trial 101 pruned. \n",
      "[I 2025-12-17 13:28:50,287] Trial 102 finished with value: 0.2158074166064557 and parameters: {'covisit_hybrid_alpha': 0.6933841688707951, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:50,664] Trial 103 finished with value: 0.2168540771658606 and parameters: {'covisit_hybrid_alpha': 0.7203610423121102, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:50,979] Trial 104 finished with value: 0.21684650712485604 and parameters: {'covisit_hybrid_alpha': 0.7199103869562767, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:51,288] Trial 105 pruned. \n",
      "[I 2025-12-17 13:28:51,633] Trial 106 pruned. \n",
      "[I 2025-12-17 13:28:51,970] Trial 107 pruned. \n",
      "[I 2025-12-17 13:28:52,379] Trial 108 pruned. \n",
      "[I 2025-12-17 13:28:52,691] Trial 109 finished with value: 0.2140945095262531 and parameters: {'covisit_hybrid_alpha': 0.7551627110956148, 'covisit_top_n_neighbors': 38}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:53,026] Trial 110 finished with value: 0.21528004446368276 and parameters: {'covisit_hybrid_alpha': 0.701114165124524, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:53,345] Trial 111 pruned. \n",
      "[I 2025-12-17 13:28:53,668] Trial 112 finished with value: 0.21777910907297565 and parameters: {'covisit_hybrid_alpha': 0.7218591827587876, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:54,091] Trial 113 finished with value: 0.21669894345456947 and parameters: {'covisit_hybrid_alpha': 0.7627580692474895, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:54,395] Trial 114 pruned. \n",
      "[I 2025-12-17 13:28:54,702] Trial 115 pruned. \n",
      "[I 2025-12-17 13:28:55,014] Trial 116 pruned. \n",
      "[I 2025-12-17 13:28:55,344] Trial 117 pruned. \n",
      "[I 2025-12-17 13:28:55,658] Trial 118 pruned. \n",
      "[I 2025-12-17 13:28:56,063] Trial 119 pruned. \n",
      "[I 2025-12-17 13:28:56,369] Trial 120 pruned. \n",
      "[I 2025-12-17 13:28:56,683] Trial 121 pruned. \n",
      "[I 2025-12-17 13:28:57,007] Trial 122 finished with value: 0.21543495565924428 and parameters: {'covisit_hybrid_alpha': 0.7033573886779776, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:57,319] Trial 123 finished with value: 0.21430470229850923 and parameters: {'covisit_hybrid_alpha': 0.7685699684964572, 'covisit_top_n_neighbors': 31}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:57,714] Trial 124 pruned. \n",
      "[I 2025-12-17 13:28:58,032] Trial 125 finished with value: 0.21514118767821985 and parameters: {'covisit_hybrid_alpha': 0.7001678381689702, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:58,341] Trial 126 finished with value: 0.21484792120834217 and parameters: {'covisit_hybrid_alpha': 0.7825747444823574, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:58,653] Trial 127 finished with value: 0.21497404804770232 and parameters: {'covisit_hybrid_alpha': 0.7757183683868719, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:58,983] Trial 128 pruned. \n",
      "[I 2025-12-17 13:28:59,364] Trial 129 finished with value: 0.21580196980204056 and parameters: {'covisit_hybrid_alpha': 0.6912401467731384, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:28:59,661] Trial 130 pruned. \n",
      "[I 2025-12-17 13:28:59,963] Trial 131 finished with value: 0.21566841643356077 and parameters: {'covisit_hybrid_alpha': 0.6942205277613427, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:00,270] Trial 132 pruned. \n",
      "[I 2025-12-17 13:29:00,565] Trial 133 pruned. \n",
      "[I 2025-12-17 13:29:00,868] Trial 134 finished with value: 0.21449418075238164 and parameters: {'covisit_hybrid_alpha': 0.687243698478, 'covisit_top_n_neighbors': 32}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:01,236] Trial 135 finished with value: 0.2168881923126932 and parameters: {'covisit_hybrid_alpha': 0.7393575073894696, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:01,539] Trial 136 pruned. \n",
      "[I 2025-12-17 13:29:01,852] Trial 137 pruned. \n",
      "[I 2025-12-17 13:29:02,183] Trial 138 pruned. \n",
      "[I 2025-12-17 13:29:02,520] Trial 139 pruned. \n",
      "[I 2025-12-17 13:29:02,905] Trial 140 finished with value: 0.2160038178573168 and parameters: {'covisit_hybrid_alpha': 0.7393547062457939, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:03,222] Trial 141 pruned. \n",
      "[I 2025-12-17 13:29:03,531] Trial 142 finished with value: 0.21666039766442444 and parameters: {'covisit_hybrid_alpha': 0.7163044793461696, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:03,843] Trial 143 finished with value: 0.21521509413945417 and parameters: {'covisit_hybrid_alpha': 0.7281702590424807, 'covisit_top_n_neighbors': 36}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:04,160] Trial 144 pruned. \n",
      "[I 2025-12-17 13:29:04,530] Trial 145 pruned. \n",
      "[I 2025-12-17 13:29:04,884] Trial 146 pruned. \n",
      "[I 2025-12-17 13:29:05,249] Trial 147 finished with value: 0.21458931814925836 and parameters: {'covisit_hybrid_alpha': 0.7478261536817932, 'covisit_top_n_neighbors': 124}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:05,575] Trial 148 pruned. \n",
      "[I 2025-12-17 13:29:05,988] Trial 149 pruned. \n",
      "[I 2025-12-17 13:29:06,334] Trial 150 pruned. \n",
      "[I 2025-12-17 13:29:06,726] Trial 151 finished with value: 0.21498154110763504 and parameters: {'covisit_hybrid_alpha': 0.7738934597278655, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:07,047] Trial 152 finished with value: 0.21650869075335663 and parameters: {'covisit_hybrid_alpha': 0.7081377901568211, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:07,378] Trial 153 pruned. \n",
      "[I 2025-12-17 13:29:07,686] Trial 154 pruned. \n",
      "[I 2025-12-17 13:29:08,018] Trial 155 pruned. \n",
      "[I 2025-12-17 13:29:08,398] Trial 156 pruned. \n",
      "[I 2025-12-17 13:29:08,696] Trial 157 pruned. \n",
      "[I 2025-12-17 13:29:08,996] Trial 158 pruned. \n",
      "[I 2025-12-17 13:29:09,326] Trial 159 pruned. \n",
      "[I 2025-12-17 13:29:09,658] Trial 160 finished with value: 0.2170396511786802 and parameters: {'covisit_hybrid_alpha': 0.7382419671580877, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:10,047] Trial 161 finished with value: 0.2153016758366788 and parameters: {'covisit_hybrid_alpha': 0.7122937255744866, 'covisit_top_n_neighbors': 32}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:10,344] Trial 162 pruned. \n",
      "[I 2025-12-17 13:29:10,649] Trial 163 finished with value: 0.21688115295937974 and parameters: {'covisit_hybrid_alpha': 0.742916297002901, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:10,969] Trial 164 pruned. \n",
      "[I 2025-12-17 13:29:11,290] Trial 165 finished with value: 0.21670642211387295 and parameters: {'covisit_hybrid_alpha': 0.7624467474150383, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:11,594] Trial 166 pruned. \n",
      "[I 2025-12-17 13:29:11,967] Trial 167 finished with value: 0.21604555429152805 and parameters: {'covisit_hybrid_alpha': 0.738797728721838, 'covisit_top_n_neighbors': 31}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:12,263] Trial 168 pruned. \n",
      "[I 2025-12-17 13:29:12,570] Trial 169 finished with value: 0.2147495356961938 and parameters: {'covisit_hybrid_alpha': 0.7401880096042857, 'covisit_top_n_neighbors': 35}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:12,875] Trial 170 finished with value: 0.21702963858877186 and parameters: {'covisit_hybrid_alpha': 0.7374741552602156, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:13,184] Trial 171 finished with value: 0.21474191967306847 and parameters: {'covisit_hybrid_alpha': 0.6749211403484989, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:13,572] Trial 172 finished with value: 0.21615776540303464 and parameters: {'covisit_hybrid_alpha': 0.7433283310674536, 'covisit_top_n_neighbors': 21}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:13,870] Trial 173 pruned. \n",
      "[I 2025-12-17 13:29:14,173] Trial 174 pruned. \n",
      "[I 2025-12-17 13:29:14,490] Trial 175 pruned. \n",
      "[I 2025-12-17 13:29:14,827] Trial 176 pruned. \n",
      "[I 2025-12-17 13:29:15,195] Trial 177 pruned. \n",
      "[I 2025-12-17 13:29:15,535] Trial 178 pruned. \n",
      "[I 2025-12-17 13:29:15,842] Trial 179 finished with value: 0.21484892932497604 and parameters: {'covisit_hybrid_alpha': 0.7458188126556269, 'covisit_top_n_neighbors': 33}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:16,167] Trial 180 finished with value: 0.215654044234242 and parameters: {'covisit_hybrid_alpha': 0.6860585869418927, 'covisit_top_n_neighbors': 20}. Best is trial 95 with value: 0.2178538033815049.\n",
      "[I 2025-12-17 13:29:16,469] Trial 181 pruned. \n",
      "[I 2025-12-17 13:29:16,783] Trial 182 finished with value: 0.21788004011967596 and parameters: {'covisit_hybrid_alpha': 0.7263601749827773, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:17,155] Trial 183 pruned. \n",
      "[I 2025-12-17 13:29:17,464] Trial 184 finished with value: 0.2158050270134002 and parameters: {'covisit_hybrid_alpha': 0.6920463538214611, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:17,764] Trial 185 finished with value: 0.21702842203822023 and parameters: {'covisit_hybrid_alpha': 0.7464780581451136, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:18,073] Trial 186 pruned. \n",
      "[I 2025-12-17 13:29:18,375] Trial 187 finished with value: 0.21788001390516384 and parameters: {'covisit_hybrid_alpha': 0.7293815933316076, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:18,752] Trial 188 finished with value: 0.2148902029422321 and parameters: {'covisit_hybrid_alpha': 0.7391656538317323, 'covisit_top_n_neighbors': 34}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:19,072] Trial 189 pruned. \n",
      "[I 2025-12-17 13:29:19,372] Trial 190 pruned. \n",
      "[I 2025-12-17 13:29:19,695] Trial 191 finished with value: 0.2178618416717252 and parameters: {'covisit_hybrid_alpha': 0.7316473021335785, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:20,019] Trial 192 pruned. \n",
      "[I 2025-12-17 13:29:20,449] Trial 193 finished with value: 0.21612147994254627 and parameters: {'covisit_hybrid_alpha': 0.7699544042005372, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:20,835] Trial 194 pruned. \n",
      "[I 2025-12-17 13:29:21,170] Trial 195 finished with value: 0.21664698311867905 and parameters: {'covisit_hybrid_alpha': 0.7149830812526751, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:21,488] Trial 196 pruned. \n",
      "[I 2025-12-17 13:29:21,805] Trial 197 pruned. \n",
      "[I 2025-12-17 13:29:22,123] Trial 198 pruned. \n",
      "[I 2025-12-17 13:29:22,540] Trial 199 pruned. \n",
      "[I 2025-12-17 13:29:22,867] Trial 200 pruned. \n",
      "[I 2025-12-17 13:29:23,178] Trial 201 finished with value: 0.21657186857131286 and parameters: {'covisit_hybrid_alpha': 0.7614245613883341, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:23,486] Trial 202 finished with value: 0.21732126340068605 and parameters: {'covisit_hybrid_alpha': 0.7514909683157733, 'covisit_top_n_neighbors': 20}. Best is trial 182 with value: 0.21788004011967596.\n",
      "[I 2025-12-17 13:29:23,793] Trial 203 pruned. \n",
      "[W 2025-12-17 13:29:24,100] Trial 204 failed with parameters: {'covisit_hybrid_alpha': 0.6778819865675837, 'covisit_top_n_neighbors': 20} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/scude/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_12776/3593789738.py\", line 36, in objective\n",
      "    eval_result = evaluate_model(\n",
      "                  ^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_12776/1065298118.py\", line 36, in evaluate_model\n",
      "    _ = recommend_func(user_id, seen, k)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_12776/3374605211.py\", line 241, in recommend\n",
      "    scores[item] = scores.get(item, 0.0) + (1 - alpha) * pop_score\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-12-17 13:29:24,103] Trial 204 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[204]\u001B[39m\u001B[32m, line 59\u001B[39m\n\u001B[32m     56\u001B[39m pruner = MedianPruner(n_startup_trials=\u001B[32m50\u001B[39m)\n\u001B[32m     58\u001B[39m study = optuna.create_study(direction=\u001B[33m\"\u001B[39m\u001B[33mmaximize\u001B[39m\u001B[33m\"\u001B[39m, sampler=sampler, pruner=pruner)\n\u001B[32m---> \u001B[39m\u001B[32m59\u001B[39m \u001B[43mstudy\u001B[49m\u001B[43m.\u001B[49m\u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobjective\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mN_TRIALS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m     61\u001B[39m best_params = study.best_params\n\u001B[32m     62\u001B[39m best_trial = study.best_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/study.py:475\u001B[39m, in \u001B[36mStudy.optimize\u001B[39m\u001B[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34moptimize\u001B[39m(\n\u001B[32m    374\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    375\u001B[39m     func: ObjectiveFuncType,\n\u001B[32m   (...)\u001B[39m\u001B[32m    382\u001B[39m     show_progress_bar: \u001B[38;5;28mbool\u001B[39m = \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    383\u001B[39m ) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    384\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Optimize an objective function.\u001B[39;00m\n\u001B[32m    385\u001B[39m \n\u001B[32m    386\u001B[39m \u001B[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    473\u001B[39m \u001B[33;03m            If nested invocation of this method occurs.\u001B[39;00m\n\u001B[32m    474\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m475\u001B[39m     \u001B[43m_optimize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    476\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    477\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    478\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    479\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    480\u001B[39m \u001B[43m        \u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_jobs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    481\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mtuple\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mIterable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    482\u001B[39m \u001B[43m        \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    483\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    484\u001B[39m \u001B[43m        \u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshow_progress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    485\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/_optimize.py:63\u001B[39m, in \u001B[36m_optimize\u001B[39m\u001B[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001B[39m\n\u001B[32m     61\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m     62\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m n_jobs == \u001B[32m1\u001B[39m:\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m         \u001B[43m_optimize_sequential\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     64\u001B[39m \u001B[43m            \u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     65\u001B[39m \u001B[43m            \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     66\u001B[39m \u001B[43m            \u001B[49m\u001B[43mn_trials\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     67\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     68\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     69\u001B[39m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     70\u001B[39m \u001B[43m            \u001B[49m\u001B[43mgc_after_trial\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     71\u001B[39m \u001B[43m            \u001B[49m\u001B[43mreseed_sampler_rng\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     72\u001B[39m \u001B[43m            \u001B[49m\u001B[43mtime_start\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[32m     73\u001B[39m \u001B[43m            \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m=\u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     74\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     76\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m n_jobs == -\u001B[32m1\u001B[39m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/_optimize.py:160\u001B[39m, in \u001B[36m_optimize_sequential\u001B[39m\u001B[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001B[39m\n\u001B[32m    157\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[32m    159\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m160\u001B[39m     frozen_trial = \u001B[43m_run_trial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstudy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    161\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    162\u001B[39m     \u001B[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001B[39;00m\n\u001B[32m    163\u001B[39m     \u001B[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001B[39;00m\n\u001B[32m    164\u001B[39m     \u001B[38;5;66;03m# Please refer to the following PR for further details:\u001B[39;00m\n\u001B[32m    165\u001B[39m     \u001B[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001B[39;00m\n\u001B[32m    166\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m gc_after_trial:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/_optimize.py:248\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    241\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[33m\"\u001B[39m\u001B[33mShould not reach.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    243\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    244\u001B[39m     frozen_trial.state == TrialState.FAIL\n\u001B[32m    245\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m func_err \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    246\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(func_err, catch)\n\u001B[32m    247\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m func_err\n\u001B[32m    249\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m frozen_trial\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/projet-4/lib/python3.11/site-packages/optuna/study/_optimize.py:197\u001B[39m, in \u001B[36m_run_trial\u001B[39m\u001B[34m(study, func, catch)\u001B[39m\n\u001B[32m    195\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001B[32m    196\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m197\u001B[39m         value_or_values = \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrial\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    198\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m exceptions.TrialPruned \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    199\u001B[39m         \u001B[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001B[39;00m\n\u001B[32m    200\u001B[39m         state = TrialState.PRUNED\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[204]\u001B[39m\u001B[32m, line 36\u001B[39m, in \u001B[36mobjective\u001B[39m\u001B[34m(trial)\u001B[39m\n\u001B[32m     27\u001B[39m top_n_neighbors = trial.suggest_int(\u001B[33m\"\u001B[39m\u001B[33mcovisit_top_n_neighbors\u001B[39m\u001B[33m\"\u001B[39m, \u001B[32m20\u001B[39m, \u001B[32m1200\u001B[39m, log=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     29\u001B[39m recommend_fn, meta = build_hybrid_covisit_recommender(\n\u001B[32m     30\u001B[39m     train_df,\n\u001B[32m     31\u001B[39m     alpha=alpha,\n\u001B[32m     32\u001B[39m     top_n_neighbors=top_n_neighbors,\n\u001B[32m     33\u001B[39m     metric=CONFIG[\u001B[33m\"\u001B[39m\u001B[33mcovisit_similarity\u001B[39m\u001B[33m\"\u001B[39m],\n\u001B[32m     34\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m eval_result = \u001B[43mevaluate_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m     37\u001B[39m \u001B[43m    \u001B[49m\u001B[33;43mf\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mModèle E3-1 - Hybride optuna (trial \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mtrial\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[33;43m)\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     38\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrecommend_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     39\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrain_histories\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     40\u001B[39m \u001B[43m    \u001B[49m\u001B[43mground_truth\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     41\u001B[39m \u001B[43m    \u001B[49m\u001B[43mcandidate_items\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     42\u001B[39m \u001B[43m    \u001B[49m\u001B[43mK\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     43\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     45\u001B[39m \u001B[38;5;66;03m# Stocker toutes les infos dans Optuna (évite les listes globales)\u001B[39;00m\n\u001B[32m     46\u001B[39m trial.set_user_attr(\u001B[33m\"\u001B[39m\u001B[33meval_result\u001B[39m\u001B[33m\"\u001B[39m, eval_result)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[192]\u001B[39m\u001B[32m, line 36\u001B[39m, in \u001B[36mevaluate_model\u001B[39m\u001B[34m(name, recommend_func, train_histories, ground_truth, candidate_items, k, latency_sample)\u001B[39m\n\u001B[32m     34\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m user_id \u001B[38;5;129;01min\u001B[39;00m sample_users:\n\u001B[32m     35\u001B[39m     seen = \u001B[38;5;28mset\u001B[39m(train_histories.get(user_id, []))\n\u001B[32m---> \u001B[39m\u001B[32m36\u001B[39m     _ = \u001B[43mrecommend_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseen\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     37\u001B[39m latency = (time.perf_counter() - start) / \u001B[38;5;28mmax\u001B[39m(\u001B[32m1\u001B[39m, \u001B[38;5;28mlen\u001B[39m(sample_users))\n\u001B[32m     39\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m {\n\u001B[32m     40\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mmodel\u001B[39m\u001B[33m\"\u001B[39m: name,\n\u001B[32m     41\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33musers\u001B[39m\u001B[33m\"\u001B[39m: \u001B[38;5;28mlen\u001B[39m(users),\n\u001B[32m   (...)\u001B[39m\u001B[32m     47\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mlatency_per_user_s\u001B[39m\u001B[33m\"\u001B[39m: latency,\n\u001B[32m     48\u001B[39m }\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[191]\u001B[39m\u001B[32m, line 241\u001B[39m, in \u001B[36mbuild_hybrid_covisit_recommender.<locals>.recommend\u001B[39m\u001B[34m(user_id, seen, k)\u001B[39m\n\u001B[32m    239\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m item \u001B[38;5;129;01min\u001B[39;00m seen:\n\u001B[32m    240\u001B[39m         \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m241\u001B[39m     scores[item] = scores.get(item, \u001B[32m0.0\u001B[39m) + (\u001B[32m1\u001B[39m - alpha) * pop_score\n\u001B[32m    242\u001B[39m ranked = \u001B[38;5;28msorted\u001B[39m(scores.items(), key=\u001B[38;5;28;01mlambda\u001B[39;00m x: x[\u001B[32m1\u001B[39m], reverse=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    243\u001B[39m recs = [it \u001B[38;5;28;01mfor\u001B[39;00m it, _ \u001B[38;5;129;01min\u001B[39;00m ranked]\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 204
  },
  {
   "cell_type": "markdown",
   "id": "b4694e82",
   "metadata": {},
   "source": [
    "## Résultats consolidés\n",
    "\n",
    "Après exécution des cinq blocs d'entraînement ci-dessus, les métriques sont agrégées pour comparer les approches. Chaque ligne du tableau récapitule la précision, le rappel, la MAP, le NDCG, la couverture et la latence moyenne par utilisateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fce6efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.683232Z",
     "iopub.status.busy": "2025-12-17T10:07:55.683015Z",
     "iopub.status.idle": "2025-12-17T10:07:55.690434Z",
     "shell.execute_reply": "2025-12-17T10:07:55.689949Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Agréger les métriques une fois les entraînements terminés\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values([\"ndcg@k\", \"map@k\"], ascending=False).reset_index(drop=True)\n",
    "(display(results_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c77eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparatif final (baseline vs E3 par défaut vs E3-1 optimisé)\n",
    "baseline_label = \"Baseline A - Popularité globale\"\n",
    "default_e3_label = f\"Modèle E3 - Hybride (alpha={CONFIG['covisit_hybrid_alpha']})\"\n",
    "optimized_label = \"Modèle E3-1 - Hybride optimisé\"\n",
    "\n",
    "comparison_df = results_df[results_df[\"model\"].isin([baseline_label, default_e3_label, optimized_label])].reset_index(drop=True)\n",
    "comparison_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fe2d39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.692949Z",
     "iopub.status.busy": "2025-12-17T10:07:55.692627Z",
     "iopub.status.idle": "2025-12-17T10:07:55.700350Z",
     "shell.execute_reply": "2025-12-17T10:07:55.699052Z"
    }
   },
   "outputs": [],
   "source": [
    "results_steps = (\n",
    "    pd.DataFrame(step_results)\n",
    "    .sort_values([\"ndcg@k\", \"precision@k\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "print(\"Tableau comparatif des variantes E (trié sur ndcg@k puis precision@k) :\")\n",
    "print(results_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deac6ae",
   "metadata": {},
   "source": [
    "## Analyse & choix du modèle MVP\n",
    "\n",
    "Le classement met en lumière des compromis :\n",
    "- **Pertinence** : la popularité globale obtient le meilleur NDCG@5/MAP@5, signe que trier par volume reste difficile à battre sur ce petit jeu synthétique.\n",
    "- **Diversité** : l'item2item couvre trois fois plus d'articles, ce qui réduit le risque d'effet tunnel.\n",
    "- **Latence** : toutes les approches sont très rapides (millisecondes), la popularité restant la plus simple.\n",
    "\n",
    "Le choix MVP bascule vers la popularité globale uniquement si l'on cherche la pertinence maximale et un déploiement express. Pour un produit, il serait pertinent de tester une hybridation : démarrer par la popularité pour les nouveaux utilisateurs puis basculer vers l'item2item dès que l'historique se construit afin d'augmenter la couverture sans sacrifier la qualité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe168bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.702573Z",
     "iopub.status.busy": "2025-12-17T10:07:55.702341Z",
     "iopub.status.idle": "2025-12-17T10:07:55.709380Z",
     "shell.execute_reply": "2025-12-17T10:07:55.708572Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "best_row = results_df.iloc[0]\n",
    "justification = f\"\"\"\n",
    "## Choix du modèle MVP\n",
    "\n",
    "Modèle retenu : **{best_row['model']}**\n",
    "\n",
    "Motifs principaux :\n",
    "- NDCG@5 = {best_row['ndcg@k']:.4f}, MAP@5 = {best_row['map@k']:.4f}, Precision@5 = {best_row['precision@k']:.4f}, Recall@5 = {best_row['recall@k']:.4f}\n",
    "- Couverture = {best_row['coverage@k']:.4f} sur {len(candidate_items)} articles candidats.\n",
    "- Latence moyenne par utilisateur = {best_row['latency_per_user_s']:.6f} s (CPU).\n",
    "- Complexité : implémentation {('légère (contenu/co-visitation)' if 'Item2Item' in best_row['model'] else 'linéaire en dimensions SVD')} compatible avec Azure Functions.\n",
    "- Gestion du cold-start utilisateur via popularité globale.\n",
    "\n",
    "Note : ajuster `content_pca_components` pour réduire la taille des embeddings en production si nécessaire.\n",
    "\"\"\"\n",
    "choice_path = Path(CONFIG[\"artifacts_dir\"]) / \"model_choice.md\"\n",
    "choice_path.write_text(justification)\n",
    "print(justification)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33525096",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T10:07:55.711931Z",
     "iopub.status.busy": "2025-12-17T10:07:55.711736Z",
     "iopub.status.idle": "2025-12-17T10:07:55.718550Z",
     "shell.execute_reply": "2025-12-17T10:07:55.717809Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "results_path_csv = Path(CONFIG[\"artifacts_dir\"]) / \"results.csv\"\n",
    "results_path_json = Path(CONFIG[\"artifacts_dir\"]) / \"results.json\"\n",
    "results_df.to_csv(results_path_csv, index=False)\n",
    "results_df.to_json(results_path_json, orient=\"records\", lines=True)\n",
    "print(f\"Résultats sauvegardés dans {results_path_csv} et {results_path_json}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7138f859",
   "metadata": {},
   "source": [
    "### Déploiement (application et Azure Functions)\n",
    "Le modèle **E3-1 - Hybride optimisé** est utilisé pour l'application Flask et la Function Azure, avec les hyperparamètres validés : `covisit_hybrid_alpha = 0.7350738721058192` et `covisit_top_n_neighbors = 20`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3854802",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook montre comment comparer des stratégies de recommandation avec une procédure reproductible : split temporel, entraînement, évaluation multi-métriques et sauvegarde des résultats. Les essais révèlent que la popularité globale reste une valeur sûre pour débuter, mais que des modèles plus personnalisés (item2item ou SVD) apportent de la diversité dès que l'on dispose d'historique. Les prochaines étapes naturelles sont d'exécuter les tests sur les vraies données Kaggle, d'ajouter des métriques business (taux de clic simulé, couverture par catégorie) et de prototyper une hybridation popularité + item2item dans une Azure Function pour valider le comportement en production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8521c810d4bf26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
