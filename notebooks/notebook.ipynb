{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773debcd",
   "metadata": {},
   "source": [
    "# Évaluation d'un système de recommandation My Content\n",
    "\n",
    "Notebook pour entraîner et comparer plusieurs approches de recommandation sur le dataset Kaggle **news-portal-user-interactions-by-globocom**. L'objectif est de montrer clairement chaque étape (du chargement des données jusqu'au choix final du modèle)."
   ]
  },
  {
   "cell_type": "code",
   "id": "43aa8131",
   "metadata": {},
   "source": [
    "# Imports & Config\n",
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Callable, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"clicks_dir\": \"../data/news-portal-user-interactions-by-globocom/clicks\",\n",
    "    \"metadata_path\": \"../data/news-portal-user-interactions-by-globocom/articles_metadata.csv\",\n",
    "    \"embeddings_path\": \"../data/news-portal-user-interactions-by-globocom/articles_embeddings.pickle\",\n",
    "    \"max_click_files\": 12,\n",
    "    \"artifacts_dir\": \"../artifacts/evaluation\",\n",
    "    \"k\": 5,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"recent_window_days\": 7,\n",
    "    \"random_seed\": 42,\n",
    "    \"svd_components\": 64,\n",
    "    \"content_pca_components\": None,\n",
    "}\n",
    "np.random.seed(CONFIG[\"random_seed\"])\n",
    "Path(CONFIG[\"artifacts_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "print(\"Config ready\", CONFIG)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "cc6be6a7",
   "metadata": {},
   "source": [
    "## Contexte\n",
    "\n",
    "Nous voulons proposer à chaque lecteur un Top-5 d'articles susceptibles de l'intéresser. Le notebook illustre la démarche de A à Z : préparation des données, construction de différentes familles de modèles puis comparaison à l'aide de métriques de ranking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07f8cfa",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les fichiers attendus sont situés dans `/data/*`."
   ]
  },
  {
   "cell_type": "code",
   "id": "116743e2",
   "metadata": {},
   "source": [
    "# Load data utilities\n",
    "\n",
    "def detect_timestamp_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Detect the timestamp-like column name.\"\"\"\n",
    "    candidates = [\"click_timestamp\", \"timestamp\", \"event_time\", \"ts\", \"time\"]\n",
    "    for col in df.columns:\n",
    "        if col in candidates or col.lower() in candidates:\n",
    "            return col\n",
    "    raise ValueError(\"No timestamp-like column found. Expected one of: \" + \",\".join(candidates))\n",
    "\n",
    "\n",
    "def detect_article_column(df: pd.DataFrame) -> str:\n",
    "    \"\"\"Detect the article/item column name.\"\"\"\n",
    "    candidates = [\"click_article_id\", \"clicked_article_id\", \"article_id\", \"item_id\", \"content_id\"]\n",
    "    for col in df.columns:\n",
    "        if col in candidates:\n",
    "            return col\n",
    "    raise ValueError(\"No article id column found. Expected one of: \" + \",\".join(candidates))\n",
    "\n",
    "\n",
    "def infer_unix_unit(values: pd.Series) -> str:\n",
    "    numeric = pd.to_numeric(values, errors=\"coerce\").dropna()\n",
    "    if numeric.empty:\n",
    "        return \"s\"\n",
    "    max_abs = numeric.abs().max()\n",
    "    if max_abs >= 1e14:\n",
    "        return \"ns\"\n",
    "    if max_abs >= 1e11:\n",
    "        return \"ms\"\n",
    "    return \"s\"\n",
    "\n",
    "\n",
    "def to_timestamp(series: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_datetime64_any_dtype(series):\n",
    "        return pd.to_datetime(series)\n",
    "    if pd.api.types.is_numeric_dtype(series):\n",
    "        unit = infer_unix_unit(series)\n",
    "        return pd.to_datetime(series, unit=unit, errors=\"coerce\")\n",
    "\n",
    "    converted = pd.to_datetime(series, errors=\"coerce\")\n",
    "    if converted.notna().any():\n",
    "        return converted\n",
    "\n",
    "    unit = infer_unix_unit(series)\n",
    "    return pd.to_datetime(series, unit=unit, errors=\"coerce\")\n",
    "\n",
    "\n",
    "def list_click_files(path: Union[str, Path]) -> List[Path]:\n",
    "    path_obj = Path(path)\n",
    "    if path_obj.is_file():\n",
    "        return [path_obj]\n",
    "    if path_obj.is_dir():\n",
    "        return sorted(path_obj.glob(\"clicks_hour_*.csv\"))\n",
    "    return []\n",
    "\n",
    "\n",
    "def create_synthetic_clicks(path: str, n_users: int = 50, n_items: int = 120, days: int = 30, interactions_per_user: int = 25) -> pd.DataFrame:\n",
    "    \"\"\"Create a small synthetic clicks dataset to keep the notebook runnable.\"\"\"\n",
    "    rng = np.random.default_rng(CONFIG[\"random_seed\"])\n",
    "    start = pd.Timestamp(\"2022-01-01\")\n",
    "    records = []\n",
    "    for user in range(1, n_users + 1):\n",
    "        offsets = rng.integers(0, days, size=interactions_per_user)\n",
    "        timestamps = [start + pd.Timedelta(int(o), unit=\"D\") for o in sorted(offsets.tolist())]\n",
    "        articles = rng.integers(1, n_items + 1, size=interactions_per_user)\n",
    "        for ts, art in zip(timestamps, articles):\n",
    "            records.append({\"user_id\": int(user), \"article_id\": int(art), \"timestamp\": ts})\n",
    "    df = pd.DataFrame(records).sort_values(\"timestamp\").reset_index(drop=True)\n",
    "    Path(path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(path, index=False)\n",
    "    print(\n",
    "        f\"Synthetic clicks dataset created at {path} \"\n",
    "        f\"(users={n_users}, items={n_items}, interactions={len(df)})\"\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_clicks(path: str, max_files: Optional[int] = None) -> pd.DataFrame:\n",
    "    \"\"\"Load clicks data from the Globo hourly files, with a safety cap.\"\"\"\n",
    "    files = list_click_files(path)\n",
    "    if not files:\n",
    "        print(f\"Clicks directory not found at {path}. Generating a synthetic sample for demonstration.\")\n",
    "        return create_synthetic_clicks(Path(path) / \"clicks_hour_000.csv\")\n",
    "\n",
    "    if max_files is not None:\n",
    "        files = files[:max_files]\n",
    "\n",
    "    frames = []\n",
    "    for file in files:\n",
    "        df = pd.read_csv(file)\n",
    "        ts_col = detect_timestamp_column(df)\n",
    "        article_col = detect_article_column(df)\n",
    "        df[ts_col] = to_timestamp(df[ts_col])\n",
    "        df = df.rename(columns={ts_col: \"timestamp\", article_col: \"article_id\"})\n",
    "        frames.append(df[[\"user_id\", \"article_id\", \"timestamp\"]])\n",
    "\n",
    "    combined = pd.concat(frames, ignore_index=True)\n",
    "    return combined.sort_values(\"timestamp\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def load_metadata(path: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Load article metadata if available.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Metadata file not found at {path}. Falling back to co-visitation content model.\")\n",
    "        return None\n",
    "    meta = pd.read_csv(path)\n",
    "    if \"article_id\" not in meta.columns:\n",
    "        print(\"Metadata missing 'article_id' column. Ignoring metadata.\")\n",
    "        return None\n",
    "    return meta\n",
    "\n",
    "\n",
    "clicks = load_clicks(CONFIG[\"clicks_dir\"], max_files=CONFIG[\"max_click_files\"])\n",
    "metadata = load_metadata(CONFIG[\"metadata_path\"])\n",
    "print(clicks.head())\n",
    "print(\"Metadata loaded:\", metadata is not None)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "eab18f0f",
   "metadata": {},
   "source": [
    "## Analyse exploratoire des données\n",
    "\n",
    "Courte photographie des fichiers sources immédiatement après le chargement :\n",
    "- nombre de lignes et noms de colonnes des clics\n",
    "- volumes et intégrité des métadonnées articles\n",
    "- dimensions et structure du fichier d'`articles_embeddings`."
   ]
  },
  {
   "cell_type": "code",
   "id": "45108db9",
   "metadata": {},
   "source": [
    "# EDA rapide sur les données sources\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from collections.abc import Mapping\n",
    "\n",
    "\n",
    "def summarize_timestamps(series: pd.Series):\n",
    "    series = pd.to_datetime(series)\n",
    "    daily = series.dt.date.value_counts().sort_index().rename_axis(\"date\").reset_index(name=\"nb_clicks\")\n",
    "    hourly = series.dt.hour.value_counts().sort_index().rename_axis(\"hour\").reset_index(name=\"nb_clicks\")\n",
    "    return series.min(), series.max(), daily, hourly\n",
    "\n",
    "\n",
    "def describe_structure(obj, prefix=\"embeddings\", max_depth=4):\n",
    "    entries = []\n",
    "\n",
    "    def add_entry(path, value, note=None):\n",
    "        entry = {\"chemin\": path, \"type\": type(value).__name__}\n",
    "        if hasattr(value, \"shape\"):\n",
    "            entry[\"shape\"] = tuple(getattr(value, \"shape\"))\n",
    "        elif hasattr(value, \"__len__\") and not isinstance(value, (str, bytes)):\n",
    "            entry[\"len\"] = len(value)\n",
    "        if hasattr(value, \"dtype\"):\n",
    "            entry[\"dtype\"] = str(getattr(value, \"dtype\"))\n",
    "        if note:\n",
    "            entry[\"note\"] = note\n",
    "        if isinstance(value, np.ndarray) and value.dtype.names:\n",
    "            entry[\"dtype_fields\"] = list(value.dtype.names)\n",
    "        if isinstance(value, np.ndarray) and value.ndim == 1 and len(value) > 0 and not isinstance(value[0], (np.ndarray, list, tuple, Mapping)):\n",
    "            entry[\"exemple\"] = repr(value[:3].tolist())\n",
    "        entries.append(entry)\n",
    "\n",
    "    def walk(value, path, depth):\n",
    "        add_entry(path, value)\n",
    "        if depth >= max_depth:\n",
    "            return\n",
    "        if isinstance(value, Mapping):\n",
    "            for k, v in value.items():\n",
    "                walk(v, f\"{path}.{k}\", depth + 1)\n",
    "        elif isinstance(value, (list, tuple, np.ndarray)) and not isinstance(value, (str, bytes)):\n",
    "            if len(value) > 0:\n",
    "                walk(value[0], f\"{path}[0]\", depth + 1)\n",
    "\n",
    "    walk(obj, prefix, 0)\n",
    "    return entries\n",
    "\n",
    "\n",
    "click_files = list_click_files(CONFIG[\"clicks_dir\"])\n",
    "print(f\"Nombre total de fichiers clicks détectés: {len(click_files)}\")\n",
    "if not click_files:\n",
    "    print(\"Aucun fichier clicks trouvé au chemin configuré. Vérifiez le téléchargement des données.\")\n",
    "\n",
    "files_for_eda = click_files[:2]\n",
    "per_file_stats = []\n",
    "for file in files_for_eda:\n",
    "    df_file = pd.read_csv(file)\n",
    "    ts_col = detect_timestamp_column(df_file)\n",
    "    article_col = detect_article_column(df_file)\n",
    "    timestamps = to_timestamp(df_file[ts_col])\n",
    "    per_file_stats.append(\n",
    "        {\n",
    "            \"fichier\": file.name,\n",
    "            \"nb_lignes\": len(df_file),\n",
    "            \"colonnes\": \", \".join(df_file.columns),\n",
    "            \"articles_uniques\": df_file[article_col].nunique(),\n",
    "            \"horodatage_min\": timestamps.min(),\n",
    "            \"horodatage_max\": timestamps.max(),\n",
    "        }\n",
    "    )\n",
    "if per_file_stats:\n",
    "    display(pd.DataFrame(per_file_stats))\n",
    "else:\n",
    "    print(\"Pas assez de fichiers pour réaliser une EDA détaillée par fichier.\")\n",
    "\n",
    "print(\"=== Clicks (agrégés) ===\")\n",
    "if clicks.empty:\n",
    "    print(\"Aucun clic chargé. Vérifier le chemin ou augmenter max_click_files.\")\n",
    "else:\n",
    "    clicks_summary = {\n",
    "        \"nb_lignes\": len(clicks),\n",
    "        \"colonnes\": \", \".join(clicks.columns),\n",
    "        \"utilisateurs_uniques\": clicks['user_id'].nunique() if 'user_id' in clicks else None,\n",
    "        \"articles_uniques\": clicks['article_id'].nunique() if 'article_id' in clicks else None,\n",
    "    }\n",
    "    display(pd.DataFrame([clicks_summary]))\n",
    "    ts_min, ts_max, daily, hourly = summarize_timestamps(clicks['timestamp'])\n",
    "    display(pd.DataFrame([\n",
    "        {\n",
    "            'horodatage_min': ts_min,\n",
    "            'horodatage_max': ts_max,\n",
    "            'fenetre_jours': (ts_max - ts_min).days + 1,\n",
    "        }\n",
    "    ]))\n",
    "    print(\"Répartition par jour (jusqu'à 10 premières valeurs)\")\n",
    "    display(daily.head(10))\n",
    "    print(\"Répartition par heure (0-23)\")\n",
    "    display(hourly)\n",
    "\n",
    "print(\"=== Métadonnées des articles ===\")\n",
    "if metadata is None:\n",
    "    print(\"Aucun fichier metadata chargé.\")\n",
    "else:\n",
    "    meta_summary = {\n",
    "        \"nb_articles\": len(metadata),\n",
    "        \"colonnes\": \", \".join(metadata.columns),\n",
    "        \"articles_uniques\": metadata['article_id'].nunique() if 'article_id' in metadata else None,\n",
    "    }\n",
    "    display(pd.DataFrame([meta_summary]))\n",
    "    missing = metadata.isna().sum().sort_values(ascending=False)\n",
    "    display(missing.to_frame('valeurs_manquantes'))\n",
    "    if 'created_at_ts' in metadata.columns:\n",
    "        created = to_timestamp(metadata['created_at_ts'])\n",
    "        display(pd.DataFrame([{'premier_article': created.min(), 'dernier_article': created.max()}]))\n",
    "    if 'article_id' in metadata.columns:\n",
    "        overlap = set(clicks['article_id'].unique()) if 'article_id' in clicks.columns else set()\n",
    "        coverage = len(overlap & set(metadata['article_id'].unique()))\n",
    "        print(f\"Articles présents dans clicks et metadata: {coverage}\")\n",
    "\n",
    "\n",
    "print(\"=== Embeddings d'articles ===\")\n",
    "embeddings_path = Path(CONFIG['embeddings_path'])\n",
    "if embeddings_path.exists():\n",
    "    with embeddings_path.open('rb') as f:\n",
    "        embeddings_obj = pickle.load(f)\n",
    "    print(f\"Type chargé: {type(embeddings_obj)}\")\n",
    "\n",
    "    def summarize_matrix(mat):\n",
    "        stats = {\n",
    "            'shape': getattr(mat, 'shape', None),\n",
    "            'dtype': getattr(mat, 'dtype', None),\n",
    "        }\n",
    "\n",
    "        dim_values = []\n",
    "        shape = getattr(mat, 'shape', None)\n",
    "        if shape is not None and len(shape) >= 2:\n",
    "            dim_values.append(shape[1])\n",
    "        elif isinstance(mat, (list, tuple, np.ndarray)):\n",
    "            for row in mat:\n",
    "                if hasattr(row, '__len__') and not isinstance(row, (str, bytes)):\n",
    "                    try:\n",
    "                        dim_values.append(len(row))\n",
    "                    except TypeError:\n",
    "                        continue\n",
    "\n",
    "        if dim_values:\n",
    "            stats.update({\n",
    "                'profondeur_min': min(dim_values),\n",
    "                'profondeur_moyenne': float(np.mean(dim_values)),\n",
    "                'profondeur_max': max(dim_values),\n",
    "            })\n",
    "\n",
    "        if hasattr(mat, 'shape') and len(getattr(mat, 'shape', [])) == 2:\n",
    "            norms = np.linalg.norm(mat, axis=1)\n",
    "            stats.update(\n",
    "                {\n",
    "                    'nb_vectors': mat.shape[0],\n",
    "                    'dim': mat.shape[1],\n",
    "                    'norm_min': norms.min(),\n",
    "                    'norm_max': norms.max(),\n",
    "                    'norm_moyenne': norms.mean(),\n",
    "                }\n",
    "            )\n",
    "        return stats\n",
    "\n",
    "    base_structure = describe_structure(embeddings_obj, max_depth=4)\n",
    "\n",
    "    if isinstance(embeddings_obj, dict):\n",
    "        keys = list(embeddings_obj.keys())\n",
    "        print(f\"Clés disponibles: {keys}\")\n",
    "        matrix = embeddings_obj.get('embeddings')\n",
    "        ids = embeddings_obj.get('articles_ids') or embeddings_obj.get('article_ids')\n",
    "\n",
    "        structure = base_structure.copy()\n",
    "        if ids is not None:\n",
    "            structure.insert(0, {\n",
    "                'chemin': 'embeddings.article_ids',\n",
    "                'type': type(ids).__name__,\n",
    "                'len': len(ids),\n",
    "                'note': \"Identifiants d'articles fournis dans le fichier\",\n",
    "            })\n",
    "        if structure:\n",
    "            print(\"Structure détaillée de l'objet d'embeddings (par chemin de clé):\")\n",
    "            display(pd.DataFrame(structure))\n",
    "\n",
    "        if matrix is not None:\n",
    "            stats = summarize_matrix(matrix)\n",
    "            stats.update(\n",
    "                {\n",
    "                    'colonnes': \", \".join(keys),\n",
    "                    'nb_articles_ids': len(ids) if ids is not None else None,\n",
    "                    'ids_uniques': len(set(ids)) if ids is not None else None,\n",
    "                    'couverture_metadata': len(set(ids) & set(metadata['article_id']))\n",
    "                    if (metadata is not None and ids is not None and 'article_id' in metadata)\n",
    "                    else None,\n",
    "                    'couverture_clicks': len(set(ids) & set(clicks['article_id']))\n",
    "                    if (not clicks.empty and ids is not None and 'article_id' in clicks)\n",
    "                    else None,\n",
    "                }\n",
    "            )\n",
    "            display(pd.DataFrame([stats]))\n",
    "\n",
    "            if ids is not None:\n",
    "                sample_ids = ids[:5] if len(ids) >= 5 else ids\n",
    "                print(\"Aperçu des premiers article_id liés aux embeddings:\")\n",
    "                display(pd.DataFrame({'article_id': sample_ids}))\n",
    "\n",
    "            preview_cols = [f\"emb_{i}\" for i in range(min(5, matrix.shape[1] if hasattr(matrix, 'shape') else 0))]\n",
    "            if preview_cols:\n",
    "                preview = pd.DataFrame(matrix[:5, : len(preview_cols)], columns=preview_cols)\n",
    "                if ids is not None:\n",
    "                    preview.insert(0, 'article_id', ids[: len(preview)])\n",
    "                print(\"Aperçu des embeddings (quelques colonnes et premières lignes):\")\n",
    "                display(preview)\n",
    "                print(\"Colonnes affichées pour l'aperçu des embeddings:\")\n",
    "                print(\", \".join(preview.columns))\n",
    "\n",
    "                if ids is not None and metadata is not None and 'article_id' in metadata:\n",
    "                    meta_cols = [c for c in ['title', 'category_id', 'created_at_ts', 'publisher'] if c in metadata.columns]\n",
    "                    meta_sample = (\n",
    "                        preview[['article_id']]\n",
    "                        .merge(metadata[['article_id'] + meta_cols], on='article_id', how='left')\n",
    "                    )\n",
    "                    if 'created_at_ts' in meta_sample.columns:\n",
    "                        meta_sample['created_at_ts'] = to_timestamp(meta_sample['created_at_ts'])\n",
    "                    print(\"Exemple de liaison embedding -> metadata sur article_id (5 premières lignes):\")\n",
    "                    display(meta_sample.head())\n",
    "        else:\n",
    "            print(\"Aucune matrice d'embeddings explicite trouvée dans l'objet chargé.\")\n",
    "    elif hasattr(embeddings_obj, 'shape'):\n",
    "        stats = summarize_matrix(embeddings_obj)\n",
    "\n",
    "        inferred_ids = None\n",
    "        mapping_note = None\n",
    "        if metadata is not None and 'article_id' in metadata and hasattr(embeddings_obj, 'shape'):\n",
    "            if embeddings_obj.shape[0] == len(metadata):\n",
    "                inferred_ids = metadata['article_id'].reset_index(drop=True)\n",
    "                mapping_note = (\n",
    "                    \"Aucun article_id explicite fourni ; association supposée alignée sur l'ordre des metadata.\"\n",
    "                )\n",
    "            else:\n",
    "                mapping_note = (\n",
    "                    \"Aucun article_id dans le fichier d'embeddings et la taille ne correspond pas aux metadata : \"\n",
    "                    f\"{embeddings_obj.shape[0]} vecteurs vs {len(metadata)} lignes de metadata.\"\n",
    "                )\n",
    "        else:\n",
    "            mapping_note = (\n",
    "                \"Aucun identifiant d'article n'est présent dans le fichier d'embeddings (mapping externe requis).\"\n",
    "            )\n",
    "\n",
    "        structure = base_structure.copy()\n",
    "        if inferred_ids is not None:\n",
    "            structure.insert(0, {\n",
    "                'chemin': 'embeddings.article_id (inféré)',\n",
    "                'type': type(inferred_ids).__name__,\n",
    "                'len': len(inferred_ids),\n",
    "                'note': \"Alignement supposé sur metadata.article_id (index identique).\",\n",
    "            })\n",
    "        if structure:\n",
    "            print(\"Structure détaillée de l'objet d'embeddings (par chemin de clé):\")\n",
    "            display(pd.DataFrame(structure))\n",
    "\n",
    "        if mapping_note:\n",
    "            print(mapping_note)\n",
    "\n",
    "        if inferred_ids is not None:\n",
    "            stats.update(\n",
    "                {\n",
    "                    'ids_source': 'metadata.article_id (alignement par index)',\n",
    "                    'ids_uniques': inferred_ids.nunique(),\n",
    "                    'couverture_metadata': len(set(inferred_ids) & set(metadata['article_id'])),\n",
    "                    'couverture_clicks': len(set(inferred_ids) & set(clicks['article_id'])) if not clicks.empty else None,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        display(pd.DataFrame([stats]))\n",
    "        if len(getattr(embeddings_obj, 'shape', [])) >= 2 and embeddings_obj.shape[1] > 0:\n",
    "            preview_cols = [f\"emb_{i}\" for i in range(min(5, embeddings_obj.shape[1]))]\n",
    "            preview = pd.DataFrame(embeddings_obj[:5, : len(preview_cols)], columns=preview_cols)\n",
    "            if inferred_ids is not None:\n",
    "                preview.insert(0, 'article_id', inferred_ids.iloc[: len(preview)].values)\n",
    "            print(\"Aperçu direct de la matrice d'embeddings:\")\n",
    "            display(preview)\n",
    "            print(\"Colonnes affichées pour l'aperçu des embeddings:\")\n",
    "            print(\", \".join(preview.columns))\n",
    "\n",
    "            if inferred_ids is not None and metadata is not None:\n",
    "                meta_cols = [c for c in ['title', 'category_id', 'created_at_ts', 'publisher'] if c in metadata.columns]\n",
    "                meta_sample = preview[['article_id']].merge(\n",
    "                    metadata[['article_id'] + meta_cols], on='article_id', how='left'\n",
    "                )\n",
    "                if 'created_at_ts' in meta_sample.columns:\n",
    "                    meta_sample['created_at_ts'] = to_timestamp(meta_sample['created_at_ts'])\n",
    "                print(\"Exemple de liaison embedding -> metadata sur article_id (inféré):\")\n",
    "                display(meta_sample.head())\n",
    "        else:\n",
    "            print(\"Objet chargé non structuré, utilisez type/len pour investiguer.\")\n",
    "else:\n",
    "    print(f\"Fichier d'embeddings introuvable à {embeddings_path}\")\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "bac08d578ddc9073",
   "metadata": {},
   "source": [
    "# Article Embeddings\n",
    "\n",
    "Ce fichier contient les **embeddings des articles**, c’est-à-dire une **représentation numérique du contenu textuel** permettant de comparer les articles entre eux sur le plan sémantique.\n",
    "\n",
    "* **Format** : matrice NumPy `(N, 250)` en `float32`\n",
    "* **1 ligne = 1 article**\n",
    "* **250 colonnes = dimensions latentes**\n",
    "* Les valeurs individuelles n’ont pas de signification directe\n",
    "\n",
    "L’`article_id` n’est **pas stocké explicitement** : il est **déduit de l’ordre des lignes**, qui doit rester aligné avec les métadonnées des articles.\n",
    "\n",
    "La variable `words_count` indique le **nombre de mots du texte source** et sert uniquement d’indicateur de qualité du contenu.\n",
    "\n",
    "Les embeddings **ne sont pas normalisés** : la **similarité cosinus** est la mesure recommandée pour comparer les articles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26424a2",
   "metadata": {},
   "source": [
    "## Protocole\n",
    "\n",
    "1. Tri des interactions par horodatage pour respecter la chronologie.\n",
    "2. Split temporel train/test selon `train_ratio` afin d'éviter toute fuite du futur.\n",
    "3. Construction d'un profil utilisateur à partir des interactions de train.\n",
    "4. Définition du *ground truth* : articles cliqués en test pour chaque utilisateur (au moins un).\n",
    "5. Génération de recommandations Top-5 en excluant les articles déjà vus en train.\n",
    "6. Calcul des métriques de ranking (Precision@5, Recall@5, MAP@5, NDCG@5, Coverage@5) et estimation de la latence moyenne sur un échantillon de 500 utilisateurs max.\n",
    "\n",
    "Cette démarche imite un scénario de production : d'abord on respecte le temps, puis on mesure simultanément la qualité des suggestions et le coût de calcul."
   ]
  },
  {
   "cell_type": "code",
   "id": "a99221f3",
   "metadata": {},
   "source": [
    "\n",
    "# Split and utility functions\n",
    "\n",
    "def temporal_train_test_split(df: pd.DataFrame, train_ratio: float) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"Split interactions chronologically according to the train_ratio.\"\"\"\n",
    "    cutoff = int(len(df) * train_ratio)\n",
    "    train = df.iloc[:cutoff].copy()\n",
    "    test = df.iloc[cutoff:].copy()\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def build_user_histories(df: pd.DataFrame) -> Dict[int, List[int]]:\n",
    "    \"\"\"Create mapping user -> list of articles in chronological order.\"\"\"\n",
    "    histories: Dict[int, List[int]] = {}\n",
    "    for user_id, group in df.groupby(\"user_id\"):\n",
    "        histories[int(user_id)] = group.sort_values(\"timestamp\")[\"article_id\"].tolist()\n",
    "    return histories\n",
    "\n",
    "\n",
    "def get_candidate_items(df: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"Return unique article ids.\"\"\"\n",
    "    return df[\"article_id\"].unique().tolist()\n",
    "\n",
    "\n",
    "def make_ground_truth(train: pd.DataFrame, test: pd.DataFrame) -> Tuple[Dict[int, List[int]], Dict[int, List[int]]]:\n",
    "    \"\"\"Build user histories and ground truth for evaluation.\"\"\"\n",
    "    train_hist = build_user_histories(train)\n",
    "    test_hist = build_user_histories(test)\n",
    "    eligible_users = {u: items for u, items in test_hist.items() if u in train_hist and len(items) > 0}\n",
    "    return train_hist, eligible_users\n",
    "\n",
    "\n",
    "train_df, test_df = temporal_train_test_split(clicks, CONFIG[\"train_ratio\"])\n",
    "train_histories, ground_truth = make_ground_truth(train_df, test_df)\n",
    "candidate_items = get_candidate_items(train_df)\n",
    "print(f\"Train size: {len(train_df)}, Test size: {len(test_df)}, Users for eval: {len(ground_truth)}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7127e6bb",
   "metadata": {},
   "source": [
    "## Modèles évalués\n",
    "\n",
    "* **Baseline A – Popularité globale** : classe les articles par nombre total de clics en train. Méthode triviale mais robuste pour les nouveaux utilisateurs.\n",
    "* **Baseline B – Popularité récente** : même idée mais limitée aux N derniers jours pour capter les tendances.\n",
    "* **Modèle C – Item2Item** : calcule une similarité entre articles (contenu TF-IDF si disponible, sinon co-visitation). On recommande les voisins les plus proches des articles déjà lus par l'utilisateur.\n",
    "* **Modèle D – Collaborative SVD** : factorisation de la matrice utilisateur-article binaire (interaction = 1) avec une SVD tronquée ; on projette utilisateurs et articles dans le même espace latent puis on recommande les articles au score le plus élevé en excluant l'historique."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35d6c96",
   "metadata": {},
   "source": [
    "## Métriques utilisées\n",
    "\n",
    "* **Precision@5** : part des recommandations top-5 qui sont réellement cliquées (plus c'est haut, plus le Top-5 est précis).\n",
    "* **Recall@5** : part des clics test retrouvés dans le Top-5 (mesure la couverture de ce que l'utilisateur aime).\n",
    "* **MAP@5** : moyenne de la précision cumulée à chaque clic retrouvé ; récompense les bonnes positions dans la liste.\n",
    "* **NDCG@5** : pondère chaque clic par sa position (gain décroissant) et normalise par le meilleur score possible ; idéal pour comparer des classements.\n",
    "* **Coverage@5** : proportion d'articles différents recommandés sur l'ensemble des utilisateurs (diversité du catalogue).\n",
    "* **Latence par utilisateur** : temps moyen pour produire le Top-5 (important pour une API temps réel)."
   ]
  },
  {
   "cell_type": "code",
   "id": "2bb3c598",
   "metadata": {},
   "source": [
    "\n",
    "# Metrics\n",
    "\n",
    "def precision_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Precision@k for a single user.\"\"\"\n",
    "    if not recommended:\n",
    "        return 0.0\n",
    "    rec_k = recommended[:k]\n",
    "    hits = len(set(rec_k) & set(relevant))\n",
    "    return hits / k\n",
    "\n",
    "\n",
    "def recall_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Recall@k for a single user.\"\"\"\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    rec_k = recommended[:k]\n",
    "    hits = len(set(rec_k) & set(relevant))\n",
    "    return hits / len(relevant)\n",
    "\n",
    "\n",
    "def average_precision_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"MAP@k for a single user.\"\"\"\n",
    "    if not relevant:\n",
    "        return 0.0\n",
    "    score = 0.0\n",
    "    hits = 0\n",
    "    for i, item in enumerate(recommended[:k], start=1):\n",
    "        if item in relevant:\n",
    "            hits += 1\n",
    "            score += hits / i\n",
    "    return score / min(len(relevant), k)\n",
    "\n",
    "\n",
    "def dcg_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Discounted cumulative gain.\"\"\"\n",
    "    dcg = 0.0\n",
    "    for i, item in enumerate(recommended[:k], start=1):\n",
    "        if item in relevant:\n",
    "            dcg += 1 / np.log2(i + 1)\n",
    "    return dcg\n",
    "\n",
    "\n",
    "def ndcg_at_k(recommended: List[int], relevant: List[int], k: int) -> float:\n",
    "    \"\"\"Normalized DCG.\"\"\"\n",
    "    ideal_dcg = dcg_at_k(relevant[:k], relevant, k)\n",
    "    if ideal_dcg == 0:\n",
    "        return 0.0\n",
    "    return dcg_at_k(recommended, relevant, k) / ideal_dcg\n",
    "\n",
    "\n",
    "def coverage_at_k(all_recommendations: List[List[int]], candidate_items: List[int], k: int) -> float:\n",
    "    \"\"\"Coverage of unique recommended items over candidates.\"\"\"\n",
    "    rec_items = set()\n",
    "    for rec in all_recommendations:\n",
    "        rec_items.update(rec[:k])\n",
    "    if not candidate_items:\n",
    "        return 0.0\n",
    "    return len(rec_items) / len(candidate_items)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "82f04b71",
   "metadata": {},
   "source": [
    "# Recommenders\n",
    "\n",
    "def build_global_popularity(train: pd.DataFrame) -> List[int]:\n",
    "    \"\"\"Return items sorted by global click counts.\"\"\"\n",
    "    return train.groupby(\"article_id\").size().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "def build_recent_popularity(train: pd.DataFrame, window_days: int) -> List[int]:\n",
    "    \"\"\"Return popular items over the last window_days of training data.\"\"\"\n",
    "    max_time = train[\"timestamp\"].max()\n",
    "    window_start = max_time - pd.Timedelta(days=window_days)\n",
    "    recent = train[train[\"timestamp\"] >= window_start]\n",
    "    return recent.groupby(\"article_id\").size().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "\n",
    "def build_covisit_graph(train: pd.DataFrame) -> Dict[int, Dict[int, int]]:\n",
    "    \"\"\"Build co-visitation counts based on user histories.\"\"\"\n",
    "    graph: Dict[int, Dict[int, int]] = {}\n",
    "    for _, group in train.groupby(\"user_id\"):\n",
    "        items = group.sort_values(\"timestamp\")[\"article_id\"].tolist()\n",
    "        unique_items = list(dict.fromkeys(items))\n",
    "        for i, item_i in enumerate(unique_items):\n",
    "            graph.setdefault(item_i, {})\n",
    "            for item_j in unique_items[i + 1 :]:\n",
    "                graph[item_i][item_j] = graph[item_i].get(item_j, 0) + 1\n",
    "                graph.setdefault(item_j, {})\n",
    "                graph[item_j][item_i] = graph[item_j].get(item_i, 0) + 1\n",
    "    return graph\n",
    "\n",
    "\n",
    "def build_content_embeddings(metadata: pd.DataFrame, pca_components: Optional[int] = None):\n",
    "    \"\"\"Create TF-IDF embeddings from textual columns with optional PCA reduction.\n",
    "\n",
    "    If no free-text columns are present, fall back to using non-ID columns as\n",
    "    categorical tokens so that content-based similarity remains available.\n",
    "    \"\"\"\n",
    "\n",
    "    text_cols = [\n",
    "        c\n",
    "        for c in metadata.columns\n",
    "        if c != \"article_id\" and pd.api.types.is_string_dtype(metadata[c])\n",
    "    ]\n",
    "    non_id_cols = [c for c in metadata.columns if c != \"article_id\"]\n",
    "\n",
    "    if not text_cols and non_id_cols:\n",
    "        print(\"No textual columns in metadata; using non-ID columns as categorical tokens.\")\n",
    "        text_cols = non_id_cols\n",
    "\n",
    "    if not text_cols:\n",
    "        raise ValueError(\"No usable columns in metadata to build content embeddings\")\n",
    "\n",
    "    corpus = metadata[text_cols].fillna(\"\")\n",
    "    corpus = corpus.apply(lambda row: \" \".join(f\"{col}_{val}\" for col, val in row.items()), axis=1)\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    tfidf = vectorizer.fit_transform(corpus)\n",
    "    if pca_components and pca_components < tfidf.shape[1]:\n",
    "        svd = TruncatedSVD(n_components=pca_components, random_state=CONFIG[\"random_seed\"])\n",
    "        reduced = svd.fit_transform(tfidf)\n",
    "        embeddings = normalize(reduced)\n",
    "    else:\n",
    "        embeddings = normalize(tfidf)\n",
    "    ids = metadata[\"article_id\"].tolist()\n",
    "    return embeddings, ids\n",
    "\n",
    "\n",
    "def build_item_similarity(train: pd.DataFrame, metadata: Optional[pd.DataFrame]):\n",
    "    \"\"\"Build item-to-item similarity either from content or co-visitation.\"\"\"\n",
    "    if metadata is not None:\n",
    "        try:\n",
    "            embeddings, ids = build_content_embeddings(metadata, CONFIG[\"content_pca_components\"])\n",
    "            similarity: Dict[int, Dict[int, float]] = {}\n",
    "            for i, aid in enumerate(ids):\n",
    "                sims = embeddings @ embeddings[i].T\n",
    "                sims = np.asarray(sims).flatten()\n",
    "                top_idx = np.argsort(-sims)[1:51]\n",
    "                similarity[aid] = {ids[j]: float(sims[j]) for j in top_idx if sims[j] > 0}\n",
    "            return similarity, \"content\"\n",
    "        except Exception as exc:\n",
    "            print(f\"Content embeddings failed ({exc}). Falling back to co-visitation.\")\n",
    "    graph = build_covisit_graph(train)\n",
    "    similarity = {item: {nbr: float(cnt) for nbr, cnt in neigh.items()} for item, neigh in graph.items()}\n",
    "    return similarity, \"covisitation\"\n",
    "\n",
    "\n",
    "def recommend_from_similarity(user_id: int, train_histories: Dict[int, List[int]], similarity: Dict[int, Dict[int, float]], candidate_items: List[int], k: int) -> List[int]:\n",
    "    \"\"\"Aggregate similarity scores from user's history.\"\"\"\n",
    "    seen = set(train_histories.get(user_id, []))\n",
    "    scores: Dict[int, float] = {}\n",
    "    for item in seen:\n",
    "        for neighbor, sim in similarity.get(item, {}).items():\n",
    "            if neighbor in seen:\n",
    "                continue\n",
    "            scores[neighbor] = scores.get(neighbor, 0.0) + sim\n",
    "    ranked = sorted(scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    recs = [it for it, _ in ranked if it not in seen]\n",
    "    if len(recs) < k:\n",
    "        for c in candidate_items:\n",
    "            if c not in seen and c not in recs:\n",
    "                recs.append(c)\n",
    "            if len(recs) >= k:\n",
    "                break\n",
    "    return recs[:k]\n",
    "\n",
    "\n",
    "def build_collaborative_svd(train: pd.DataFrame, n_components: int):\n",
    "    \"\"\"Train a simple implicit SVD recommender returning a recommend function.\"\"\"\n",
    "    users = train[\"user_id\"].unique().tolist()\n",
    "    items = train[\"article_id\"].unique().tolist()\n",
    "    user_to_idx = {u: i for i, u in enumerate(users)}\n",
    "    item_to_idx = {it: i for i, it in enumerate(items)}\n",
    "\n",
    "    rows = [user_to_idx[u] for u in train[\"user_id\"]]\n",
    "    cols = [item_to_idx[it] for it in train[\"article_id\"]]\n",
    "    data = np.ones(len(rows))\n",
    "    mat = sparse.coo_matrix((data, (rows, cols)), shape=(len(users), len(items))).tocsr()\n",
    "\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=CONFIG[\"random_seed\"])\n",
    "    user_factors = svd.fit_transform(mat)\n",
    "    item_factors = svd.components_.T\n",
    "\n",
    "    user_norm = normalize(user_factors)\n",
    "    item_norm = normalize(item_factors)\n",
    "\n",
    "    def recommend(user_id: int, seen: set, k: int) -> List[int]:\n",
    "        if user_id not in user_to_idx:\n",
    "            popularity = build_global_popularity(train)\n",
    "            return [it for it in popularity if it not in seen][:k]\n",
    "        u_vec = user_norm[user_to_idx[user_id]]\n",
    "        scores = item_norm @ u_vec\n",
    "        ranked_items = [items[i] for i in np.argsort(-scores)]\n",
    "        return [it for it in ranked_items if it not in seen][:k]\n",
    "\n",
    "    meta = {\"users\": len(users), \"items\": len(items), \"components\": n_components}\n",
    "    return recommend, meta\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a2a633fb",
   "metadata": {},
   "source": [
    "\n",
    "# Evaluation pipeline\n",
    "\n",
    "def evaluate_model(\n",
    "    name: str,\n",
    "    recommend_func: Callable[[int, set, int], List[int]],\n",
    "    train_histories: Dict[int, List[int]],\n",
    "    ground_truth: Dict[int, List[int]],\n",
    "    candidate_items: List[int],\n",
    "    k: int,\n",
    "    latency_sample: int = 500,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Evaluate a recommender with ranking metrics and latency estimation.\"\"\"\n",
    "    precisions: List[float] = []\n",
    "    recalls: List[float] = []\n",
    "    maps: List[float] = []\n",
    "    ndcgs: List[float] = []\n",
    "    all_recs: List[List[int]] = []\n",
    "\n",
    "    users = list(ground_truth.keys())\n",
    "    for user_id in users:\n",
    "        seen = set(train_histories.get(user_id, []))\n",
    "        recs = recommend_func(user_id, seen, k)\n",
    "        gt = ground_truth[user_id]\n",
    "        all_recs.append(recs)\n",
    "        precisions.append(precision_at_k(recs, gt, k))\n",
    "        recalls.append(recall_at_k(recs, gt, k))\n",
    "        maps.append(average_precision_at_k(recs, gt, k))\n",
    "        ndcgs.append(ndcg_at_k(recs, gt, k))\n",
    "\n",
    "    coverage = coverage_at_k(all_recs, candidate_items, k)\n",
    "\n",
    "    sample_users = users[: min(latency_sample, len(users))]\n",
    "    start = time.perf_counter()\n",
    "    for user_id in sample_users:\n",
    "        seen = set(train_histories.get(user_id, []))\n",
    "        _ = recommend_func(user_id, seen, k)\n",
    "    latency = (time.perf_counter() - start) / max(1, len(sample_users))\n",
    "\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"users\": len(users),\n",
    "        \"precision@k\": float(np.mean(precisions)),\n",
    "        \"recall@k\": float(np.mean(recalls)),\n",
    "        \"map@k\": float(np.mean(maps)),\n",
    "        \"ndcg@k\": float(np.mean(ndcgs)),\n",
    "        \"coverage@k\": coverage,\n",
    "        \"latency_per_user_s\": latency,\n",
    "    }\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "c71df81d",
   "metadata": {},
   "source": [
    "## Entraînement des systèmes de recommandation\n",
    "\n",
    "Chaque approche est entraînée séparément pour limiter le temps d'exécution de chaque cellule et mieux contextualiser le rôle de chaque modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53f3017",
   "metadata": {},
   "source": [
    "### Popularité globale\n",
    "La recommandation par popularité globale trie les articles par volume d'interactions dans l'ensemble d'entraînement. Elle est rapide à calculer (simple agrégation) et sert de baseline robuste pour comparer les modèles plus avancés."
   ]
  },
  {
   "cell_type": "code",
   "id": "77fe52f9",
   "metadata": {},
   "source": [
    "# Configuration commune\n",
    "K = CONFIG[\"k\"]\n",
    "\n",
    "# Popularité globale\n",
    "popularity_rank = build_global_popularity(train_df)\n",
    "\n",
    "def popularity_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return [it for it in popularity_rank if it not in seen][:k]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b431ac4",
   "metadata": {},
   "source": [
    "### Popularité récente\n",
    "Cette variante privilégie la fraîcheur en filtrant les interactions sur une fenêtre temporelle avant de trier les articles par fréquence. Utile pour capter les tendances du moment, au prix d'un recalcul plus fréquent de la fenêtre glissante."
   ]
  },
  {
   "cell_type": "code",
   "id": "13812520",
   "metadata": {},
   "source": [
    "# Popularité récente\n",
    "recent_rank = build_recent_popularity(train_df, CONFIG[\"recent_window_days\"])\n",
    "\n",
    "def recent_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return [it for it in recent_rank if it not in seen][:k]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f83ee1f5",
   "metadata": {},
   "source": [
    "### Contenu (similarité article-article)\n",
    "Un modèle basé contenu construit une matrice de similarité entre articles à partir des métadonnées. Les recommandations se font en projetant l'historique utilisateur vers les items proches dans cet espace. Ce calcul peut être plus coûteux car il nécessite la vectorisation et le produit croisé des articles."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb98dec3",
   "metadata": {},
   "source": [
    "# Recommandation basée contenu\n",
    "item_similarity, sim_mode = build_item_similarity(train_df, metadata)\n",
    "\n",
    "def content_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return recommend_from_similarity(user_id, train_histories, item_similarity, candidate_items, k)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b8fa4833",
   "metadata": {},
   "source": [
    "### Collaborative (SVD)\n",
    "Le filtrage collaboratif factorise la matrice utilisateur-item (SVD) pour capturer des préférences latentes. L'entraînement est plus long que les méthodes de popularité ou de similarité de contenu, mais il modélise mieux les affinités implicites entre utilisateurs et articles."
   ]
  },
  {
   "cell_type": "code",
   "id": "2ffed396",
   "metadata": {},
   "source": [
    "# Filtrage collaboratif (SVD)\n",
    "collab_recommend, collab_meta = build_collaborative_svd(train_df, CONFIG[\"svd_components\"])\n",
    "\n",
    "def collaborative_recommender(user_id: int, seen: set, k: int) -> List[int]:\n",
    "    return collab_recommend(user_id, seen, k)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "18f18670",
   "metadata": {},
   "source": [
    "\n",
    "## Entraînements séparés\n",
    "\n",
    "Les quatre stratégies sont désormais exécutées dans des cellules distinctes afin de pouvoir lancer, arrêter ou relancer chaque bloc indépendamment. Cela évite d'attendre l'ensemble du pipeline quand un seul entraînement est nécessaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4ea5563c",
   "metadata": {},
   "source": [
    "\n",
    "# Initialiser un conteneur de résultats pour chaque entraînement\n",
    "results = []\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce250ec4",
   "metadata": {},
   "source": [
    "\n",
    "### Entraînement 1 : Baseline A – Popularité globale\n",
    "\n",
    "Cette approche classe les articles par nombre total de clics dans l'historique d'entraînement. Aucun paramètre n'est appris : on calcule simplement le classement global une fois, puis on recommande les articles les plus populaires que l'utilisateur n'a pas encore vus. C'est la référence la plus rapide et la plus robuste pour les nouveaux utilisateurs.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "051c24a1",
   "metadata": {},
   "source": [
    "\n",
    "popularity_result = evaluate_model(\n",
    "    \"Baseline A - Popularité globale\",\n",
    "    popularity_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(popularity_result)\n",
    "pd.DataFrame([popularity_result])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6a9a988f",
   "metadata": {},
   "source": [
    "\n",
    "### Entraînement 2 : Baseline B – Popularité récente\n",
    "\n",
    "On privilégie ici les tendances courantes en recalculant le classement des articles sur la fenêtre temporelle récente (définie par `CONFIG['recent_window_days']`). Le modèle est recalculé à chaque changement de fenêtre pour capturer les effets de mode tout en restant très léger à entraîner.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "c168b7ce",
   "metadata": {},
   "source": [
    "\n",
    "recent_result = evaluate_model(\n",
    "    f\"Baseline B - Popularité {CONFIG['recent_window_days']}j\",\n",
    "    recent_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(recent_result)\n",
    "pd.DataFrame([recent_result])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a2a5ca11",
   "metadata": {},
   "source": [
    "\n",
    "### Entraînement 3 : Modèle C – Item2Item\n",
    "\n",
    "Le modèle item2item construit une matrice de similarité entre articles (TF-IDF contenu ou co-visitation suivant la disponibilité des métadonnées). Pour chaque utilisateur, on agrège les articles les plus proches de son historique en excluant les items déjà vus. L'entraînement consiste à calculer cette matrice de similarité, opération plus coûteuse que la popularité mais toujours raisonnable sur le dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "2e057fca",
   "metadata": {},
   "source": [
    "\n",
    "item2item_result = evaluate_model(\n",
    "    f\"Modèle C - Item2Item ({sim_mode})\",\n",
    "    content_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(item2item_result)\n",
    "pd.DataFrame([item2item_result])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "98df36bf",
   "metadata": {},
   "source": [
    "\n",
    "### Entraînement 4 : Modèle D – Collaborative SVD\n",
    "\n",
    "La factorisation de matrice SVD projette utilisateurs et articles dans un espace latent de dimension `CONFIG['svd_components']`. On entraîne le modèle sur la matrice binaire utilisateur-article (clic = 1), puis on recommande les articles au score latent maximal, toujours en excluant l'historique. Ce bloc est le plus long mais offre une baseline collaborative pour comparer aux approches basées sur le contenu.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "80518873",
   "metadata": {},
   "source": [
    "\n",
    "svd_result = evaluate_model(\n",
    "    \"Modèle D - Collaborative SVD\",\n",
    "    collaborative_recommender,\n",
    "    train_histories,\n",
    "    ground_truth,\n",
    "    candidate_items,\n",
    "    K,\n",
    ")\n",
    "results.append(svd_result)\n",
    "pd.DataFrame([svd_result])\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b4694e82",
   "metadata": {},
   "source": [
    "\n",
    "## Résultats consolidés\n",
    "\n",
    "Après exécution des quatre blocs d'entraînement ci-dessus, les métriques sont agrégées pour comparer les approches. Chaque ligne du tableau récapitule la précision, le rappel, la MAP, le NDCG, la couverture et la latence moyenne par utilisateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "4fce6efd",
   "metadata": {},
   "source": [
    "\n",
    "# Agréger les métriques une fois les quatre entraînements terminés\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values([\"ndcg@k\", \"map@k\"], ascending=False).reset_index(drop=True)\n",
    "print(results_df)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2deac6ae",
   "metadata": {},
   "source": [
    "## Analyse & choix du modèle MVP\n",
    "\n",
    "Le classement met en lumière des compromis :\n",
    "- **Pertinence** : la popularité globale obtient le meilleur NDCG@5/MAP@5, signe que trier par volume reste difficile à battre sur ce petit jeu synthétique.\n",
    "- **Diversité** : l'item2item couvre trois fois plus d'articles, ce qui réduit le risque d'effet tunnel.\n",
    "- **Latence** : toutes les approches sont très rapides (millisecondes), la popularité restant la plus simple.\n",
    "\n",
    "Le choix MVP bascule vers la popularité globale uniquement si l'on cherche la pertinence maximale et un déploiement express. Pour un produit, il serait pertinent de tester une hybridation : démarrer par la popularité pour les nouveaux utilisateurs puis basculer vers l'item2item dès que l'historique se construit afin d'augmenter la couverture sans sacrifier la qualité."
   ]
  },
  {
   "cell_type": "code",
   "id": "dbe168bd",
   "metadata": {},
   "source": [
    "\n",
    "best_row = results_df.iloc[0]\n",
    "justification = f\"\"\"\n",
    "## Choix du modèle MVP\n",
    "\n",
    "Modèle retenu : **{best_row['model']}**\n",
    "\n",
    "Motifs principaux :\n",
    "- NDCG@5 = {best_row['ndcg@k']:.4f}, MAP@5 = {best_row['map@k']:.4f}, Precision@5 = {best_row['precision@k']:.4f}, Recall@5 = {best_row['recall@k']:.4f}\n",
    "- Couverture = {best_row['coverage@k']:.4f} sur {len(candidate_items)} articles candidats.\n",
    "- Latence moyenne par utilisateur = {best_row['latency_per_user_s']:.6f} s (CPU).\n",
    "- Complexité : implémentation {('légère (contenu/co-visitation)' if 'Item2Item' in best_row['model'] else 'linéaire en dimensions SVD')} compatible avec Azure Functions.\n",
    "- Gestion du cold-start utilisateur via popularité globale.\n",
    "\n",
    "Note : ajuster `content_pca_components` pour réduire la taille des embeddings en production si nécessaire.\n",
    "\"\"\"\n",
    "choice_path = Path(CONFIG[\"artifacts_dir\"]) / \"model_choice.md\"\n",
    "choice_path.write_text(justification)\n",
    "print(justification)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "33525096",
   "metadata": {},
   "source": [
    "\n",
    "results_path_csv = Path(CONFIG[\"artifacts_dir\"]) / \"results.csv\"\n",
    "results_path_json = Path(CONFIG[\"artifacts_dir\"]) / \"results.json\"\n",
    "results_df.to_csv(results_path_csv, index=False)\n",
    "results_df.to_json(results_path_json, orient=\"records\", lines=True)\n",
    "print(f\"Résultats sauvegardés dans {results_path_csv} et {results_path_json}\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e3854802",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook montre comment comparer des stratégies de recommandation avec une procédure reproductible : split temporel, entraînement, évaluation multi-métriques et sauvegarde des résultats. Les essais révèlent que la popularité globale reste une valeur sûre pour débuter, mais que des modèles plus personnalisés (item2item ou SVD) apportent de la diversité dès que l'on dispose d'historique. Les prochaines étapes naturelles sont d'exécuter les tests sur les vraies données Kaggle, d'ajouter des métriques business (taux de clic simulé, couverture par catégorie) et de prototyper une hybridation popularité + item2item dans une Azure Function pour valider le comportement en production."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
